{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Universidad Internacional de La Rioja (UNIR) - Máster Universitario en Inteligencia Artificial - Procesamiento del Lenguaje Natural** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Datos del alumno (Nombre y Apellidos):\n",
    "\n",
    "Fecha:\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20pt; font-weight: bold; color: #0098cd;\">Trabajo: Named-Entity Recognition</span>\n",
    "\n",
    "**Objetivos** \n",
    "\n",
    "Con esta actividad se tratará de que el alumno se familiarice con el manejo de la librería spacy, así como con los conceptos básicos de manejo de las técnicas NER\n",
    "\n",
    "**Descripción**\n",
    "\n",
    "En esta actividad debes procesar de forma automática un texto en lenguaje natural para detectar características básicas en el mismo, y para identificar y etiquetar las ocurrencias de conceptos como localización, moneda, empresas, etc.\n",
    "\n",
    "En la primera parte del ejercicio se proporciona un código fuente a través del cual se lee un archivo de texto y se realiza un preprocesado del mismo. En esta parte el alumno tan sólo debe ejecutar y entender el código proporcionado.\n",
    "\n",
    "En la segunda parte del ejercicio se plantean una serie de preguntas que deben ser respondidas por el alumno. Cada pregunta deberá responderse con un fragmento de código fuente que esté acompañado de la explicación correspondiente. Para elaborar el código solicitado, el alumno deberá visitar la documentación de la librería spacy, cuyos enlaces se proporcionarán donde corresponda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: carga y preprocesamiento del texto a analizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa las diferentes librerías que se están importando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "import csv\n",
    "import es_core_news_md\n",
    "\n",
    "#import es_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código simplemente carga y preprocesa el texto. Para ello, lo primero que hace es cargar un modelo de lenguaje previamente entrenado. En este caso, se utiliza <i>es_core_news_md</i>: \n",
    "\n",
    "https://spacy.io/models/es#es_core_news_md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = es_core_news_md.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objeto <i>nlp</i> permite utilizar el modelo de lenguaje cargado, de forma que se puede procesar un texto y obtenerlo en su versión preprocesada. Así, nos permite realizar las diferentes tareas. En este caso, vamos a utilizar el pipeline para hacer un preprocesamiento básico, que consiste en tokenizar el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./comentariosOdio.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccmarc4\\AppData\\Local\\Temp\\ipykernel_10684\\916618882.py:2: DtypeWarning: Columns (5,6,7,8,9,10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(filename, delimiter=';', encoding='latin1')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lines_number = 20\n",
    "data = pd.read_csv(filename, delimiter=';', encoding='latin1')  \n",
    "#data = pd.read_csv(filename, delimiter=';',nrows=lines_number)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código anterior carga el archivo CSV (opcionalmente con un límite de líneas a leer) y genera la variable <i>data</i>, que contiene un Dataframe (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) con los datos leídos del CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Te vendrá bien conocer la siguiente documentación:\n",
    "<ul>\n",
    "    <li>https://spacy.io/api/doc</li>\n",
    "    <li>https://spacy.io/api/token</li>\n",
    "    <li>https://spacy.io/api/morphology#morphanalysis</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground\n",
    "\n",
    "Utiliza este espacio para hacer pruebas y ensayos con las variables generadas con el código previo. A modo de ejemplo, se ofrece código que realiza las siguientes tareas: \n",
    "\n",
    "\n",
    "- leer un número dado de líneas del Dataframe y generar dos listas con los valores (se pueden leer directamente del DataFrame, se muestra el ejemplo como una opción más)\n",
    "- procesar el texto de cada comentario\n",
    "\n",
    "\n",
    "Para procesarlo, hay utilizar el objeto <i>nlp</i> y así obtener objetos de la clase <i>Doc</i> (https://spacy.io/api/doc)\n",
    "\n",
    "Visita la documentación de dicha clase y experimenta probando las diferentes funciones y atributos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puedes insertar aquí código de pruebas para experimentar con las diferentes funciones y atributos de 'doc'.\n",
    "#print(data[\"CONTENIDO A ANALIZAR\"][1])\n",
    "#print(data[\"INTENSIDAD\"][1])\n",
    "doc = []\n",
    "value = []\n",
    "\n",
    "#con el bucle, generamos sendas listas con los comentarios ya parseados y con el valor de intensidad\n",
    "for i in range(0, lines_number):#'''len(data[\"CONTENIDO A ANALIZAR\"])'''\n",
    "    \n",
    "    #en un primer paso se parsea el comentario. En el segundo paso se añade el objeto a la lista\n",
    "    tmp_doc = nlp(data[\"CONTENIDO A ANALIZAR\"][i])\n",
    "    doc.append(tmp_doc)\n",
    "    \n",
    "    #en un primer paso extrae el valor. En el segundo paso se añade el valor a la lista\n",
    "    tmp_value = data[\"INTENSIDAD\"][i]\n",
    "    value.append(tmp_value)\n",
    "\n",
    "\n",
    "# #ejemplo de cómo recorrer un comentario palabra por palabra    \n",
    "# for token in doc[1]:\n",
    "#     print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 1.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cuántos registros contiene el corpus?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He visto que hay varios problemas en el dataset:\n",
    "- Muchas filas en las que todos los valores son nulos menos 1, que es la continuación del contenido de la fila anterior. Para arreglar esto borraré las filas que solo contengan ese valor.\n",
    "- Hay varias columnas más de las que son en verdad. Esto se debe a que hay direcciones, nombres y demás mal tabulados. Borraré todas las columnas que no tengan un nombre definido, ya que estas columnas en realidad no tienen nombre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fila con datos en columna excedente (Unnamed: 9):\n",
      "MEDIO                                                           alcoi, 66\n",
      "SOPORTE                                                    en mislata, 62\n",
      "URL                                                           en elda, 61\n",
      "TIPO DE MENSAJE                                              en xàbia, 59\n",
      "CONTENIDO A ANALIZAR                                      el campello, 53\n",
      "INTENSIDAD                                             la vila joiosa, 52\n",
      "TIPO DE ODIO                                     burjassot y l'eliana, 51\n",
      "TONO HUMORISTICO                                              godella, 49\n",
      "MODIFICADOR                                                   manises, 48\n",
      "Unnamed: 9                                                    alfafar, 47\n",
      "Unnamed: 10                                                     puçol, 46\n",
      "Unnamed: 11                                                benicàssim, 45\n",
      "Unnamed: 12                               benicarló, petrer y vinaròs, 44\n",
      "Unnamed: 13                                           algemesí y calp, 43\n",
      "Unnamed: 14              aldaia, la pobla de vallbona, 42 y borriana y...\n",
      "Unnamed: 15                                                           0.0\n",
      "Name: 122844, dtype: object\n",
      "----------------------------------------\n",
      "Fila con datos en columna excedente (Unnamed: 9):\n",
      "MEDIO                                                           alcoi, 66\n",
      "SOPORTE                                                    en mislata, 62\n",
      "URL                                                           en elda, 61\n",
      "TIPO DE MENSAJE                                              en xàbia, 59\n",
      "CONTENIDO A ANALIZAR                                      el campello, 53\n",
      "INTENSIDAD                                             la vila joiosa, 52\n",
      "TIPO DE ODIO                                     burjassot y l'eliana, 51\n",
      "TONO HUMORISTICO                                              godella, 49\n",
      "MODIFICADOR                                                   manises, 48\n",
      "Unnamed: 9                                                    alfafar, 47\n",
      "Unnamed: 10                                                     puçol, 46\n",
      "Unnamed: 11                                                benicàssim, 45\n",
      "Unnamed: 12                               benicarló, petrer y vinaròs, 44\n",
      "Unnamed: 13                                           algemesí y calp, 43\n",
      "Unnamed: 14              aldaia, la pobla de vallbona, 42 y borriana y...\n",
      "Unnamed: 15                                                           0.0\n",
      "Name: 122880, dtype: object\n",
      "----------------------------------------\n",
      "Fila con datos en columna excedente (Unnamed: 9):\n",
      "MEDIO                   ad del cliente, se negó a responder preguntas ...\n",
      "SOPORTE                                               le monde de francia\n",
      "URL                                               malaysiakjni de malasia\n",
      "TIPO DE MENSAJE                                   stand news de hong kong\n",
      "CONTENIDO A ANALIZAR                            occrp e istories en rusia\n",
      "INTENSIDAD                                      tanya kozyreva en ucrania\n",
      "TIPO DE ODIO             australian broadcasting corp. y australian fi...\n",
      "TONO HUMORISTICO                              karlijn kuijpers en holanda\n",
      "MODIFICADOR                          the guardian y la bbc en reino unido\n",
      "Unnamed: 9               the washington post, the miami herald y the w...\n",
      "Unnamed: 10                                                           0.0\n",
      "Unnamed: 11                                                           NaN\n",
      "Unnamed: 12                                                           NaN\n",
      "Unnamed: 13                                                           NaN\n",
      "Unnamed: 14                                                           NaN\n",
      "Unnamed: 15                                                           NaN\n",
      "Name: 504362, dtype: object\n",
      "----------------------------------------\n",
      "Fila con datos en columna excedente (Unnamed: 10):\n",
      "MEDIO                                                           alcoi, 66\n",
      "SOPORTE                                                    en mislata, 62\n",
      "URL                                                           en elda, 61\n",
      "TIPO DE MENSAJE                                              en xàbia, 59\n",
      "CONTENIDO A ANALIZAR                                      el campello, 53\n",
      "INTENSIDAD                                             la vila joiosa, 52\n",
      "TIPO DE ODIO                                     burjassot y l'eliana, 51\n",
      "TONO HUMORISTICO                                              godella, 49\n",
      "MODIFICADOR                                                   manises, 48\n",
      "Unnamed: 9                                                    alfafar, 47\n",
      "Unnamed: 10                                                     puçol, 46\n",
      "Unnamed: 11                                                benicàssim, 45\n",
      "Unnamed: 12                               benicarló, petrer y vinaròs, 44\n",
      "Unnamed: 13                                           algemesí y calp, 43\n",
      "Unnamed: 14              aldaia, la pobla de vallbona, 42 y borriana y...\n",
      "Unnamed: 15                                                           0.0\n",
      "Name: 122844, dtype: object\n",
      "----------------------------------------\n",
      "Fila con datos en columna excedente (Unnamed: 10):\n",
      "MEDIO                                                           alcoi, 66\n",
      "SOPORTE                                                    en mislata, 62\n",
      "URL                                                           en elda, 61\n",
      "TIPO DE MENSAJE                                              en xàbia, 59\n",
      "CONTENIDO A ANALIZAR                                      el campello, 53\n",
      "INTENSIDAD                                             la vila joiosa, 52\n",
      "TIPO DE ODIO                                     burjassot y l'eliana, 51\n",
      "TONO HUMORISTICO                                              godella, 49\n",
      "MODIFICADOR                                                   manises, 48\n",
      "Unnamed: 9                                                    alfafar, 47\n",
      "Unnamed: 10                                                     puçol, 46\n",
      "Unnamed: 11                                                benicàssim, 45\n",
      "Unnamed: 12                               benicarló, petrer y vinaròs, 44\n",
      "Unnamed: 13                                           algemesí y calp, 43\n",
      "Unnamed: 14              aldaia, la pobla de vallbona, 42 y borriana y...\n",
      "Unnamed: 15                                                           0.0\n",
      "Name: 122880, dtype: object\n",
      "----------------------------------------\n",
      "Fila con datos en columna excedente (Unnamed: 10):\n",
      "MEDIO                   ad del cliente, se negó a responder preguntas ...\n",
      "SOPORTE                                               le monde de francia\n",
      "URL                                               malaysiakjni de malasia\n",
      "TIPO DE MENSAJE                                   stand news de hong kong\n",
      "CONTENIDO A ANALIZAR                            occrp e istories en rusia\n",
      "INTENSIDAD                                      tanya kozyreva en ucrania\n",
      "TIPO DE ODIO             australian broadcasting corp. y australian fi...\n",
      "TONO HUMORISTICO                              karlijn kuijpers en holanda\n",
      "MODIFICADOR                          the guardian y la bbc en reino unido\n",
      "Unnamed: 9               the washington post, the miami herald y the w...\n",
      "Unnamed: 10                                                           0.0\n",
      "Unnamed: 11                                                           NaN\n",
      "Unnamed: 12                                                           NaN\n",
      "Unnamed: 13                                                           NaN\n",
      "Unnamed: 14                                                           NaN\n",
      "Unnamed: 15                                                           NaN\n",
      "Name: 504362, dtype: object\n",
      "----------------------------------------\n",
      "Fila con datos en columna excedente (Unnamed: 11):\n",
      "MEDIO                                                           alcoi, 66\n",
      "SOPORTE                                                    en mislata, 62\n",
      "URL                                                           en elda, 61\n",
      "TIPO DE MENSAJE                                              en xàbia, 59\n",
      "CONTENIDO A ANALIZAR                                      el campello, 53\n",
      "INTENSIDAD                                             la vila joiosa, 52\n",
      "TIPO DE ODIO                                     burjassot y l'eliana, 51\n",
      "TONO HUMORISTICO                                              godella, 49\n",
      "MODIFICADOR                                                   manises, 48\n",
      "Unnamed: 9                                                    alfafar, 47\n",
      "Unnamed: 10                                                     puçol, 46\n",
      "Unnamed: 11                                                benicàssim, 45\n",
      "Unnamed: 12                               benicarló, petrer y vinaròs, 44\n",
      "Unnamed: 13                                           algemesí y calp, 43\n",
      "Unnamed: 14              aldaia, la pobla de vallbona, 42 y borriana y...\n",
      "Unnamed: 15                                                           0.0\n",
      "Name: 122844, dtype: object\n",
      "----------------------------------------\n",
      "Fila con datos en columna excedente (Unnamed: 11):\n",
      "MEDIO                                                           alcoi, 66\n",
      "SOPORTE                                                    en mislata, 62\n",
      "URL                                                           en elda, 61\n",
      "TIPO DE MENSAJE                                              en xàbia, 59\n",
      "CONTENIDO A ANALIZAR                                      el campello, 53\n",
      "INTENSIDAD                                             la vila joiosa, 52\n",
      "TIPO DE ODIO                                     burjassot y l'eliana, 51\n",
      "TONO HUMORISTICO                                              godella, 49\n",
      "MODIFICADOR                                                   manises, 48\n",
      "Unnamed: 9                                                    alfafar, 47\n",
      "Unnamed: 10                                                     puçol, 46\n",
      "Unnamed: 11                                                benicàssim, 45\n",
      "Unnamed: 12                               benicarló, petrer y vinaròs, 44\n",
      "Unnamed: 13                                           algemesí y calp, 43\n",
      "Unnamed: 14              aldaia, la pobla de vallbona, 42 y borriana y...\n",
      "Unnamed: 15                                                           0.0\n",
      "Name: 122880, dtype: object\n",
      "----------------------------------------\n",
      "Fila con datos en columna excedente (Unnamed: 12):\n",
      "MEDIO                                                           alcoi, 66\n",
      "SOPORTE                                                    en mislata, 62\n",
      "URL                                                           en elda, 61\n",
      "TIPO DE MENSAJE                                              en xàbia, 59\n",
      "CONTENIDO A ANALIZAR                                      el campello, 53\n",
      "INTENSIDAD                                             la vila joiosa, 52\n",
      "TIPO DE ODIO                                     burjassot y l'eliana, 51\n",
      "TONO HUMORISTICO                                              godella, 49\n",
      "MODIFICADOR                                                   manises, 48\n",
      "Unnamed: 9                                                    alfafar, 47\n",
      "Unnamed: 10                                                     puçol, 46\n",
      "Unnamed: 11                                                benicàssim, 45\n",
      "Unnamed: 12                               benicarló, petrer y vinaròs, 44\n",
      "Unnamed: 13                                           algemesí y calp, 43\n",
      "Unnamed: 14              aldaia, la pobla de vallbona, 42 y borriana y...\n",
      "Unnamed: 15                                                           0.0\n",
      "Name: 122844, dtype: object\n",
      "----------------------------------------\n",
      "Fila con datos en columna excedente (Unnamed: 12):\n",
      "MEDIO                                                           alcoi, 66\n",
      "SOPORTE                                                    en mislata, 62\n",
      "URL                                                           en elda, 61\n",
      "TIPO DE MENSAJE                                              en xàbia, 59\n",
      "CONTENIDO A ANALIZAR                                      el campello, 53\n",
      "INTENSIDAD                                             la vila joiosa, 52\n",
      "TIPO DE ODIO                                     burjassot y l'eliana, 51\n",
      "TONO HUMORISTICO                                              godella, 49\n",
      "MODIFICADOR                                                   manises, 48\n",
      "Unnamed: 9                                                    alfafar, 47\n",
      "Unnamed: 10                                                     puçol, 46\n",
      "Unnamed: 11                                                benicàssim, 45\n",
      "Unnamed: 12                               benicarló, petrer y vinaròs, 44\n",
      "Unnamed: 13                                           algemesí y calp, 43\n",
      "Unnamed: 14              aldaia, la pobla de vallbona, 42 y borriana y...\n",
      "Unnamed: 15                                                           0.0\n",
      "Name: 122880, dtype: object\n",
      "----------------------------------------\n",
      "Fila con datos en columna excedente (Unnamed: 13):\n",
      "MEDIO                                                           alcoi, 66\n",
      "SOPORTE                                                    en mislata, 62\n",
      "URL                                                           en elda, 61\n",
      "TIPO DE MENSAJE                                              en xàbia, 59\n",
      "CONTENIDO A ANALIZAR                                      el campello, 53\n",
      "INTENSIDAD                                             la vila joiosa, 52\n",
      "TIPO DE ODIO                                     burjassot y l'eliana, 51\n",
      "TONO HUMORISTICO                                              godella, 49\n",
      "MODIFICADOR                                                   manises, 48\n",
      "Unnamed: 9                                                    alfafar, 47\n",
      "Unnamed: 10                                                     puçol, 46\n",
      "Unnamed: 11                                                benicàssim, 45\n",
      "Unnamed: 12                               benicarló, petrer y vinaròs, 44\n",
      "Unnamed: 13                                           algemesí y calp, 43\n",
      "Unnamed: 14              aldaia, la pobla de vallbona, 42 y borriana y...\n",
      "Unnamed: 15                                                           0.0\n",
      "Name: 122844, dtype: object\n",
      "----------------------------------------\n",
      "Fila con datos en columna excedente (Unnamed: 13):\n",
      "MEDIO                                                           alcoi, 66\n",
      "SOPORTE                                                    en mislata, 62\n",
      "URL                                                           en elda, 61\n",
      "TIPO DE MENSAJE                                              en xàbia, 59\n",
      "CONTENIDO A ANALIZAR                                      el campello, 53\n",
      "INTENSIDAD                                             la vila joiosa, 52\n",
      "TIPO DE ODIO                                     burjassot y l'eliana, 51\n",
      "TONO HUMORISTICO                                              godella, 49\n",
      "MODIFICADOR                                                   manises, 48\n",
      "Unnamed: 9                                                    alfafar, 47\n",
      "Unnamed: 10                                                     puçol, 46\n",
      "Unnamed: 11                                                benicàssim, 45\n",
      "Unnamed: 12                               benicarló, petrer y vinaròs, 44\n",
      "Unnamed: 13                                           algemesí y calp, 43\n",
      "Unnamed: 14              aldaia, la pobla de vallbona, 42 y borriana y...\n",
      "Unnamed: 15                                                           0.0\n",
      "Name: 122880, dtype: object\n",
      "----------------------------------------\n",
      "Fila con datos en columna excedente (Unnamed: 14):\n",
      "MEDIO                                                           alcoi, 66\n",
      "SOPORTE                                                    en mislata, 62\n",
      "URL                                                           en elda, 61\n",
      "TIPO DE MENSAJE                                              en xàbia, 59\n",
      "CONTENIDO A ANALIZAR                                      el campello, 53\n",
      "INTENSIDAD                                             la vila joiosa, 52\n",
      "TIPO DE ODIO                                     burjassot y l'eliana, 51\n",
      "TONO HUMORISTICO                                              godella, 49\n",
      "MODIFICADOR                                                   manises, 48\n",
      "Unnamed: 9                                                    alfafar, 47\n",
      "Unnamed: 10                                                     puçol, 46\n",
      "Unnamed: 11                                                benicàssim, 45\n",
      "Unnamed: 12                               benicarló, petrer y vinaròs, 44\n",
      "Unnamed: 13                                           algemesí y calp, 43\n",
      "Unnamed: 14              aldaia, la pobla de vallbona, 42 y borriana y...\n",
      "Unnamed: 15                                                           0.0\n",
      "Name: 122844, dtype: object\n",
      "----------------------------------------\n",
      "Fila con datos en columna excedente (Unnamed: 14):\n",
      "MEDIO                                                           alcoi, 66\n",
      "SOPORTE                                                    en mislata, 62\n",
      "URL                                                           en elda, 61\n",
      "TIPO DE MENSAJE                                              en xàbia, 59\n",
      "CONTENIDO A ANALIZAR                                      el campello, 53\n",
      "INTENSIDAD                                             la vila joiosa, 52\n",
      "TIPO DE ODIO                                     burjassot y l'eliana, 51\n",
      "TONO HUMORISTICO                                              godella, 49\n",
      "MODIFICADOR                                                   manises, 48\n",
      "Unnamed: 9                                                    alfafar, 47\n",
      "Unnamed: 10                                                     puçol, 46\n",
      "Unnamed: 11                                                benicàssim, 45\n",
      "Unnamed: 12                               benicarló, petrer y vinaròs, 44\n",
      "Unnamed: 13                                           algemesí y calp, 43\n",
      "Unnamed: 14              aldaia, la pobla de vallbona, 42 y borriana y...\n",
      "Unnamed: 15                                                           0.0\n",
      "Name: 122880, dtype: object\n",
      "----------------------------------------\n",
      "Fila con datos en columna excedente (Unnamed: 15):\n",
      "MEDIO                                                           alcoi, 66\n",
      "SOPORTE                                                    en mislata, 62\n",
      "URL                                                           en elda, 61\n",
      "TIPO DE MENSAJE                                              en xàbia, 59\n",
      "CONTENIDO A ANALIZAR                                      el campello, 53\n",
      "INTENSIDAD                                             la vila joiosa, 52\n",
      "TIPO DE ODIO                                     burjassot y l'eliana, 51\n",
      "TONO HUMORISTICO                                              godella, 49\n",
      "MODIFICADOR                                                   manises, 48\n",
      "Unnamed: 9                                                    alfafar, 47\n",
      "Unnamed: 10                                                     puçol, 46\n",
      "Unnamed: 11                                                benicàssim, 45\n",
      "Unnamed: 12                               benicarló, petrer y vinaròs, 44\n",
      "Unnamed: 13                                           algemesí y calp, 43\n",
      "Unnamed: 14              aldaia, la pobla de vallbona, 42 y borriana y...\n",
      "Unnamed: 15                                                           0.0\n",
      "Name: 122844, dtype: object\n",
      "----------------------------------------\n",
      "Fila con datos en columna excedente (Unnamed: 15):\n",
      "MEDIO                                                           alcoi, 66\n",
      "SOPORTE                                                    en mislata, 62\n",
      "URL                                                           en elda, 61\n",
      "TIPO DE MENSAJE                                              en xàbia, 59\n",
      "CONTENIDO A ANALIZAR                                      el campello, 53\n",
      "INTENSIDAD                                             la vila joiosa, 52\n",
      "TIPO DE ODIO                                     burjassot y l'eliana, 51\n",
      "TONO HUMORISTICO                                              godella, 49\n",
      "MODIFICADOR                                                   manises, 48\n",
      "Unnamed: 9                                                    alfafar, 47\n",
      "Unnamed: 10                                                     puçol, 46\n",
      "Unnamed: 11                                                benicàssim, 45\n",
      "Unnamed: 12                               benicarló, petrer y vinaròs, 44\n",
      "Unnamed: 13                                           algemesí y calp, 43\n",
      "Unnamed: 14              aldaia, la pobla de vallbona, 42 y borriana y...\n",
      "Unnamed: 15                                                           0.0\n",
      "Name: 122880, dtype: object\n",
      "----------------------------------------\n",
      "Columnas eliminadas: 7\n",
      "Filas afectadas por columnas eliminadas: 16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Configura el nombre de tu archivo CSV original y el de salida\n",
    "input_file = \"comentariosOdio.csv\"\n",
    "output_file = \"comentariosOdioLimpio.csv\"\n",
    "\n",
    "# Lee el archivo con utf-8 y evita errores de codificación\n",
    "try:\n",
    "    with open(input_file, encoding='utf-8', errors='replace') as file:\n",
    "        df = pd.read_csv(file, delimiter=';', engine='python')\n",
    "except Exception as e:\n",
    "    print(f\"Error al leer el archivo: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Guarda el número de columnas base (número de columnas en la primera fila)\n",
    "num_columnas_base = 9\n",
    "\n",
    "# Encuentra columnas con índice mayor al número de columnas base\n",
    "exceso_columnas = df.columns[num_columnas_base:]\n",
    "\n",
    "# Lista para almacenar las filas con datos en columnas excedentes\n",
    "filas_con_datos_excedentes = []\n",
    "\n",
    "# Verifica si alguna de las columnas excedentes tiene datos\n",
    "for col in exceso_columnas:\n",
    "    if df[col].notnull().any():\n",
    "        # Obtén las filas donde esta columna tiene datos\n",
    "        filas_con_datos = df[df[col].notnull()]\n",
    "        filas_con_datos_excedentes.append(filas_con_datos)\n",
    "        # Imprime cada fila que tiene datos en una columna excedente\n",
    "        for idx, fila in filas_con_datos.iterrows():\n",
    "            print(f\"Fila con datos en columna excedente ({col}):\")\n",
    "            print(fila)\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "# Elimina las columnas excedentes del DataFrame\n",
    "df = df.iloc[:, :num_columnas_base]\n",
    "\n",
    "# Imprime un resumen\n",
    "print(f\"Columnas eliminadas: {len(exceso_columnas)}\")\n",
    "print(f\"Filas afectadas por columnas eliminadas: {sum([len(f) for f in filas_con_datos_excedentes])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpiar el df quitando todas las columnas menos CONTENIDO A ANALIZAR e INTENSIDAD\n",
    "df = df[[\"CONTENIDO A ANALIZAR\", \"INTENSIDAD\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas en el DataFrame: 485712\n"
     ]
    }
   ],
   "source": [
    "# Si la fila es nula o duplicada, eliminar\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# contar cuantas filas tiene el df\n",
    "print(f\"Filas en el DataFrame: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo limpio guardado como 'comentariosOdioLimpio.csv'\n"
     ]
    }
   ],
   "source": [
    "# Guarda el archivo limpio\n",
    "try:\n",
    "    df.to_csv(output_file, sep=';', index=False, encoding='utf-8')\n",
    "    print(f\"Archivo limpio guardado como '{output_file}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar el archivo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas con valores nulos: Empty DataFrame\n",
      "Columns: [CONTENIDO A ANALIZAR, INTENSIDAD]\n",
      "Index: []\n",
      "Filas duplicadas: 0\n"
     ]
    }
   ],
   "source": [
    "# Buscar filas nulas o repetidas\n",
    "\n",
    "# Crea una lista de filas con valores nulos\n",
    "filas_nulas = df[df.isnull().any(axis=1)]\n",
    "\n",
    "# Crea una lista de filas duplicadas\n",
    "filas_duplicadas = df[df.duplicated()]\n",
    "\n",
    "# Imprime un resumen\n",
    "print(f\"Columnas con valores nulos: {filas_nulas}\")\n",
    "print(f\"Filas duplicadas: {len(filas_duplicadas)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    "\n",
    "Después de limpiar el dataset de columnas innecesarias, filas nulas y valores duplicados, el dataset contiene 485712 registros si miramos el número de filas del CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 2.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cuántas palabras totales hay en los comentarios del corpus?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de palabras en el corpus: 60518520\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"comentariosOdioLimpio.csv\", delimiter=';', encoding= 'utf-8')\n",
    "\n",
    "if \"CONTENIDO A ANALIZAR\" in data.columns:\n",
    "    # Combinar todos los comentarios de la columna en un solo texto\n",
    "    texto_completo = \" \".join(data[\"CONTENIDO A ANALIZAR\"].astype(str))\n",
    "\n",
    "    # Contar las palabras\n",
    "    numero_palabras = len(texto_completo.split())\n",
    "\n",
    "    print(f\"Número total de palabras en el corpus: {numero_palabras}\")\n",
    "else:\n",
    "    print(\"La columna 'CONTENIDO A ANALIZAR' no existe en el dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    "\n",
    "Después de eliminar las columnas repetidas, nulas y las columnas que no son relevantes, si revisamos el contenido de la columna de comentarios llamada \"CONTENIDO A ANALIZAR\", podemos contar las palabras y obseravamos que el corpus contiene un total de 60518520 palabras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 3.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cuál el número promedio de palabras en cada comentario?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contar_palabras(texto):\n",
    "    if isinstance(texto, str):\n",
    "        return len(texto.split())\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número promedio de palabras por comentario: 124.5975392825378\n",
      "\n",
      "Estadísticas adicionales:\n",
      "count    485712.000000\n",
      "mean        124.597539\n",
      "std         272.501166\n",
      "min           0.000000\n",
      "25%          10.000000\n",
      "50%          19.000000\n",
      "75%          59.000000\n",
      "max        5341.000000\n",
      "Name: num_palabras, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "columna = \"CONTENIDO A ANALIZAR\"\n",
    "if columna in data.columns:\n",
    "\n",
    "    comentarios = data[columna]\n",
    "    \n",
    "    # Aplicamos la función a cada comentario\n",
    "    data[\"num_palabras\"] = comentarios.apply(contar_palabras)\n",
    "    \n",
    "    # Calcular el promedio de palabras por comentario\n",
    "    promedio = data[\"num_palabras\"].mean()\n",
    "    \n",
    "    print(f\"Número promedio de palabras por comentario: {promedio}\")\n",
    "    \n",
    "    print(\"\\nEstadísticas adicionales:\")\n",
    "    print(data[\"num_palabras\"].describe())\n",
    "else:\n",
    "    print(f\"La columna '{columna}' no existe en el dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    "\n",
    "Si guardamso el número de palabras de cada fila y después aplicamos la función mean(), podemos ver que el número medio de palabras por comentario es de aproximadamente  124.6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 4.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio) ¿Cuál el número promedio de palabras en los comentarios de cada grupo?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a verficar el tipo de dato de la columna INTENSIDAD ya que en caso de no ser numérica, la deberemos de pasar a tipo numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     3.0\n",
      "1     0.0\n",
      "2     3.0\n",
      "3     3.0\n",
      "4     3.0\n",
      "5     3.0\n",
      "6     4.0\n",
      "7     3.0\n",
      "8     4.0\n",
      "9     3.0\n",
      "10    3.0\n",
      "11    4.0\n",
      "12    0.0\n",
      "13    4.0\n",
      "14    4.0\n",
      "15    3.0\n",
      "16    0.0\n",
      "17    3.0\n",
      "18    0.0\n",
      "19    0.0\n",
      "Name: INTENSIDAD, dtype: object\n",
      "object\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "#implrimir 20 valores de la comlumna INTENSIDAD y su type\n",
    "print(data[\"INTENSIDAD\"].head(20))\n",
    "print(data[\"INTENSIDAD\"].dtype)\n",
    "\n",
    "# Convertir la columna INTENSIDAD a tipo numérico\n",
    "data[\"INTENSIDAD\"] = pd.to_numeric(data[\"INTENSIDAD\"], errors='coerce')\n",
    "\n",
    "# Verificar si la conversión fue exitosa\n",
    "print(data[\"INTENSIDAD\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número promedio de palabras por comentario (sin odio): 127.16041126120524\n",
      "Número promedio de palabras por comentario (con odio): 16.69876630868909\n"
     ]
    }
   ],
   "source": [
    "# media de palabras por comentario si intensidad == 0 y para intensidad >0\n",
    "\n",
    "# Filtrar comentarios con intensidad 0\n",
    "comentarios_no_odio = data[data[\"INTENSIDAD\"] == 0]\n",
    "\n",
    "# Filtrar comentarios con intensidad mayor a 0\n",
    "comentarios_odio = data[data[\"INTENSIDAD\"] > 0]\n",
    "\n",
    "# Calcular el promedio de palabras por comentario\n",
    "promedio_no_odio = comentarios_no_odio[\"num_palabras\"].mean()\n",
    "promedio_odio = comentarios_odio[\"num_palabras\"].mean()\n",
    "\n",
    "print(f\"Número promedio de palabras por comentario (sin odio): {promedio_no_odio}\")\n",
    "print(f\"Número promedio de palabras por comentario (con odio): {promedio_odio}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#borrar columna\n",
    "data = data.drop(columns=[\"num_palabras\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    " \n",
    "Si filtramos los datos de filas donde no se dice si hay odio y en las que si hay odio y luego hacemos la media de la columna num_palabras la cual contiene el número de palabras del comentario, podemos ver que la media de palabras en comentarios de odio es de 16.69, mientras que la media de palabras en comentarios que no son de odio es de 127.16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 5.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio) ¿Cuál es el número promedio de oraciones en los comentarios de cada grupo?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contar_oraciones(texto):\n",
    "    if pd.isna(texto):  # Manejar valores nulos\n",
    "        return 0\n",
    "    # Dividir el texto por delimitadores de oraciones y contar\n",
    "    oraciones = re.split(r'[.!?]', str(texto))\n",
    "    return len([oracion for oracion in oraciones if oracion.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número promedio de oraciones por comentario (sin odio): 6.077790166574277\n",
      "Número promedio de oraciones por comentario (con odio): 1.7523741901127186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccmarc4\\AppData\\Local\\Temp\\ipykernel_10684\\1189685917.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comentarios_no_odio[\"num_oraciones\"] = comentarios_no_odio[\"CONTENIDO A ANALIZAR\"].apply(contar_oraciones)\n",
      "C:\\Users\\ccmarc4\\AppData\\Local\\Temp\\ipykernel_10684\\1189685917.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comentarios_odio[\"num_oraciones\"] = comentarios_odio[\"CONTENIDO A ANALIZAR\"].apply(contar_oraciones)\n"
     ]
    }
   ],
   "source": [
    "# contar nº de oraciones en cada comentario de odio o no odio\n",
    "\n",
    "# Filtrar comentarios con intensidad 0\n",
    "comentarios_no_odio = data[data[\"INTENSIDAD\"] == 0]\n",
    "\n",
    "# Filtrar comentarios con intensidad mayor a 0\n",
    "comentarios_odio = data[data[\"INTENSIDAD\"] > 0]\n",
    "\n",
    "# Aplicar la función a cada comentario\n",
    "comentarios_no_odio[\"num_oraciones\"] = comentarios_no_odio[\"CONTENIDO A ANALIZAR\"].apply(contar_oraciones)\n",
    "comentarios_odio[\"num_oraciones\"] = comentarios_odio[\"CONTENIDO A ANALIZAR\"].apply(contar_oraciones)\n",
    "\n",
    "# Calcular el promedio de oraciones por comentario\n",
    "promedio_no_odio = comentarios_no_odio[\"num_oraciones\"].mean()\n",
    "promedio_odio = comentarios_odio[\"num_oraciones\"].mean()\n",
    "\n",
    "print(f\"Número promedio de oraciones por comentario (sin odio): {promedio_no_odio}\")\n",
    "print(f\"Número promedio de oraciones por comentario (con odio): {promedio_odio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    " \n",
    "Las oraciones se suelen separar por \".\", \"?\" o \"!\", por lo que si separamos las oraciones por ahí y contamos las oraciones que tiene cada fila, guardándola en la columna num_oraciones, podremos calcular el promedio de oraciones por tipo de comentario. El promedio de oraciones en comentarios de odio es de aproximadamente 1.75 oraciones, mientras que el promedio de oraciones en comentarios que no son de odio es de aproximadamente 6.08."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 6.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio) ¿Cuál es el porcentaje de comentarios que contienen entidades NER en cada grupo?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de ahora, tras muchos experimentos donde me daba un error en el kernel, tal y como ha dicho el profesor en las clases online voy a usar una muestra significativa del dataset para que no tenga problemas.Tras probar varios números de filas, he conseguido llegar a usar 35.000 filas, por lo que usaré una muestra de ese tamaño para continuar.\n",
    "\n",
    "Las filas serán seleccionadas aleatoriamente con una seed para que sea reproducible e intente tener los menos sesgos posibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(n=35000, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número promedio de palabras por comentario: 125.26768571428572\n",
      "\n",
      "Estadísticas adicionales:\n",
      "count    35000.000000\n",
      "mean       125.267686\n",
      "std        272.214444\n",
      "min          1.000000\n",
      "25%         10.000000\n",
      "50%         19.000000\n",
      "75%         60.000000\n",
      "max       5154.000000\n",
      "Name: num_palabras, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "columna = \"CONTENIDO A ANALIZAR\"\n",
    "if columna in data.columns:\n",
    "\n",
    "    comentarios = data[columna]\n",
    "    \n",
    "    # Aplicamos la función a cada comentario\n",
    "    data[\"num_palabras\"] = comentarios.apply(contar_palabras)\n",
    "    \n",
    "    # Calcular el promedio de palabras por comentario\n",
    "    promedio = data[\"num_palabras\"].mean()\n",
    "    \n",
    "    print(f\"Número promedio de palabras por comentario: {promedio}\")\n",
    "    \n",
    "    print(\"\\nEstadísticas adicionales:\")\n",
    "    print(data[\"num_palabras\"].describe())\n",
    "else:\n",
    "    print(f\"La columna '{columna}' no existe en el dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número promedio de palabras por comentario (sin odio): 127.77589079535822\n",
      "Número promedio de palabras por comentario (con odio): 16.512040557667934\n"
     ]
    }
   ],
   "source": [
    "# media de palabras por comentario si intensidad == 0 y para intensidad >0\n",
    "\n",
    "# Filtrar comentarios con intensidad 0\n",
    "comentarios_no_odio = data[data[\"INTENSIDAD\"] == 0]\n",
    "\n",
    "# Filtrar comentarios con intensidad mayor a 0\n",
    "comentarios_odio = data[data[\"INTENSIDAD\"] > 0]\n",
    "\n",
    "# Calcular el promedio de palabras por comentario\n",
    "promedio_no_odio = comentarios_no_odio[\"num_palabras\"].mean()\n",
    "promedio_odio = comentarios_odio[\"num_palabras\"].mean()\n",
    "\n",
    "print(f\"Número promedio de palabras por comentario (sin odio): {promedio_no_odio}\")\n",
    "print(f\"Número promedio de palabras por comentario (con odio): {promedio_odio}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número promedio de oraciones por comentario (sin odio): 5.907748969629651\n",
      "Número promedio de oraciones por comentario (con odio): 1.6007604562737643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccmarc4\\AppData\\Local\\Temp\\ipykernel_10684\\432337394.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comentarios_no_odio[\"num_oraciones\"] = comentarios_no_odio[\"CONTENIDO A ANALIZAR\"].apply(contar_oraciones)\n",
      "C:\\Users\\ccmarc4\\AppData\\Local\\Temp\\ipykernel_10684\\432337394.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comentarios_odio[\"num_oraciones\"] = comentarios_odio[\"CONTENIDO A ANALIZAR\"].apply(contar_oraciones)\n"
     ]
    }
   ],
   "source": [
    "# Filtrar comentarios con intensidad 0\n",
    "comentarios_no_odio = data[data[\"INTENSIDAD\"] == 0]\n",
    "\n",
    "# Filtrar comentarios con intensidad mayor a 0\n",
    "comentarios_odio = data[data[\"INTENSIDAD\"] > 0]\n",
    "\n",
    "# Aplicar la función a cada comentario\n",
    "comentarios_no_odio[\"num_oraciones\"] = comentarios_no_odio[\"CONTENIDO A ANALIZAR\"].apply(contar_oraciones)\n",
    "comentarios_odio[\"num_oraciones\"] = comentarios_odio[\"CONTENIDO A ANALIZAR\"].apply(contar_oraciones)\n",
    "\n",
    "# Calcular el promedio de oraciones por comentario\n",
    "promedio_no_odio = comentarios_no_odio[\"num_oraciones\"].mean()\n",
    "promedio_odio = comentarios_odio[\"num_oraciones\"].mean()\n",
    "\n",
    "print(f\"Número promedio de oraciones por comentario (sin odio): {promedio_no_odio}\")\n",
    "print(f\"Número promedio de oraciones por comentario (con odio): {promedio_odio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras probar varias seeds, he determinado que '3' es válida ya que tiene casi el mismo número de palabras por comentario, casi el mismo numero de oraciones por comentario de odio o no odio y un numero de palabras por comentario de odio o no odio muy parecido al del dataset original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[\"num_palabras\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Contar las palabras en \"CONTENIDO A ANALIZAR\"\n",
    "# data['word_count'] = data['CONTENIDO A ANALIZAR'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# # Filtrar las filas con más de 1000 palabras\n",
    "# rows_with_many_words = data[data['word_count'] > 2000]\n",
    "\n",
    "# # Mostrar el número de filas y sus índices\n",
    "# print(f\"Número de filas con más de 1000 palabras: {len(rows_with_many_words)}\")\n",
    "# print(rows_with_many_words[['CONTENIDO A ANALIZAR', 'word_count']])\n",
    "\n",
    "#data = data[data['word_count']<=500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a responder a la pregunta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para aplicar NER en lotes usando nlp.pipe\n",
    "def detect_ner_in_batches(texts, batch_size=50):\n",
    "    has_ner = []\n",
    "    for doc in nlp.pipe(texts, batch_size=batch_size, disable=[\"tagger\", \"parser\"]):  # Solo NER\n",
    "        has_ner.append(len(doc.ents) > 0)\n",
    "    return has_ner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de comentarios con NER (odio): 39.16%\n",
      "Porcentaje de comentarios con NER (no odio): 59.42%\n"
     ]
    }
   ],
   "source": [
    "# Dividir en dos grupos (trabajando con copias explícitas para evitar el SettingWithCopyWarning)\n",
    "odio = data[data['INTENSIDAD'] > 0.0].copy()\n",
    "no_odio = data[data['INTENSIDAD'] == 0.0].copy()\n",
    "\n",
    "# Procesar comentarios con spaCy en lotes y asignar los resultados\n",
    "odio.loc[:, 'has_ner'] = detect_ner_in_batches(odio['CONTENIDO A ANALIZAR'], batch_size=50)\n",
    "no_odio.loc[:, 'has_ner'] = detect_ner_in_batches(no_odio['CONTENIDO A ANALIZAR'], batch_size=50)\n",
    "\n",
    "# Calcular porcentajes\n",
    "porcentaje_ner_odio = (odio['has_ner'].mean()) * 100\n",
    "porcentaje_ner_no_odio = (no_odio['has_ner'].mean()) * 100\n",
    "\n",
    "print(f\"Porcentaje de comentarios con NER (odio): {porcentaje_ner_odio:.2f}%\")\n",
    "print(f\"Porcentaje de comentarios con NER (no odio): {porcentaje_ner_no_odio:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    " \n",
    "Tras usar 35k comentarios, y buscar en cada comentario si el número de entidades NER es mayor que 0 (doc.ents) podemos ver los porcentajes:\n",
    "\n",
    "Porcentaje de comentarios con NER (odio): 39.16%\n",
    "Porcentaje de comentarios con NER (no odio): 59.42%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 7.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio) ¿Cuál es el porcentaje de comentarios que contienen entidades NER de tipo PERSON en cada grupo?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_person_entity(texts, batch_size=50):\n",
    "    has_person = []\n",
    "    for doc in nlp.pipe(texts, batch_size=batch_size, disable=[\"tagger\", \"parser\"]):  # Solo NER\n",
    "        # Verificar si hay al menos una entidad de tipo \"PERSON\"\n",
    "        has_person.append(any(ent.label_ == \"PER\" for ent in doc.ents))\n",
    "    return has_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de comentarios con entidades PERSON (odio): 16.98%\n",
      "Porcentaje de comentarios con entidades PERSON (no odio): 32.42%\n"
     ]
    }
   ],
   "source": [
    "# Dividir en dos grupos (trabajando con copias explícitas para evitar el SettingWithCopyWarning)\n",
    "odio = data[data['INTENSIDAD'] > 0.0].copy()\n",
    "no_odio = data[data['INTENSIDAD'] == 0.0].copy()\n",
    "\n",
    "# Procesar comentarios con spaCy en lotes y asignar los resultados\n",
    "odio.loc[:, 'has_person'] = has_person_entity(odio['CONTENIDO A ANALIZAR'], batch_size=50)\n",
    "no_odio.loc[:, 'has_person'] = has_person_entity(no_odio['CONTENIDO A ANALIZAR'], batch_size=50)\n",
    "\n",
    "# Calcular porcentajes\n",
    "porcentaje_person_odio = (odio['has_person'].mean()) * 100\n",
    "porcentaje_person_no_odio = (no_odio['has_person'].mean()) * 100\n",
    "\n",
    "print(f\"Porcentaje de comentarios con entidades PERSON (odio): {porcentaje_person_odio:.2f}%\")\n",
    "print(f\"Porcentaje de comentarios con entidades PERSON (no odio): {porcentaje_person_no_odio:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    "\n",
    "En este apartado solamente tenemos que comprobar si hay alguna entidad NER de tipo PER en el comentario (doc.label_ == \"PER\") si el output es TRUE, se contabiliza como que hay al menos una entidad de tipo PER. Tras analizarlo, podemos ver los porcentajes:\n",
    "\n",
    "Porcentaje de comentarios con entidades PERSON (odio): 16,98%\n",
    "Porcentaje de comentarios con entidades PERSON (no odio): 32.42%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 8.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio) ¿Cuál es el porcentaje de palabras en cada combinación posible de género y número (p.ej. masculino singular) en cada grupo?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentajes por género y número (grupo odio):\n",
      "('Masc', 'Sing'): 39.82%\n",
      "('Fem', 'Plur'): 8.49%\n",
      "('Masc', 'Plur'): 19.16%\n",
      "('Fem', 'Sing'): 32.53%\n",
      "\n",
      "Porcentajes por género y número (grupo no odio):\n",
      "('Masc', 'Sing'): 41.03%\n",
      "('Fem', 'Sing'): 33.46%\n",
      "('Masc', 'Plur'): 14.97%\n",
      "('Fem', 'Plur'): 10.54%\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def analyze_gender_number_debug(texts, batch_size=50):\n",
    "    # Contadores para género y número\n",
    "    counts = Counter()\n",
    "    total_relevant_words = 0\n",
    "\n",
    "    # Procesar textos en lotes\n",
    "    for doc in nlp.pipe(texts, batch_size=batch_size, disable=[\"ner\", \"parser\"]):  # Solo análisis léxico\n",
    "        for token in doc:\n",
    "            # Mostrar token y su información morfosintáctica\n",
    "            #print(f\"Token: {token.text}, Morph: {token.morph}\")\n",
    "\n",
    "            # Consideramos solo palabras con información de género y número\n",
    "            gender = token.morph.get(\"Gender\")\n",
    "            number = token.morph.get(\"Number\")\n",
    "            \n",
    "            if gender and number:  # Solo si ambos atributos existen\n",
    "                #print(f\"Palabra: {token.text}, Género: {gender[0]}, Número: {number[0]}\")\n",
    "                counts[(gender[0], number[0])] += 1\n",
    "                total_relevant_words += 1\n",
    "            #else:\n",
    "                #print(f\"Palabra: {token.text} no tiene género o número relevante\")\n",
    "\n",
    "    # Calcular porcentajes\n",
    "    percentages = {k: (v / total_relevant_words) * 100 for k, v in counts.items()} if total_relevant_words > 0 else {}\n",
    "\n",
    "    return counts, percentages\n",
    "\n",
    "# Analizar género y número para cada grupo de comentarios\n",
    "counts_odio, percentages_odio = analyze_gender_number_debug(odio['CONTENIDO A ANALIZAR'], batch_size=50)\n",
    "counts_no_odio, percentages_no_odio = analyze_gender_number_debug(no_odio['CONTENIDO A ANALIZAR'], batch_size=50)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Porcentajes por género y número (grupo odio):\")\n",
    "for k, v in percentages_odio.items():\n",
    "    print(f\"{k}: {v:.2f}%\")\n",
    "\n",
    "print(\"\\nPorcentajes por género y número (grupo no odio):\")\n",
    "for k, v in percentages_no_odio.items():\n",
    "    print(f\"{k}: {v:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    "Con la librería collections, podemos generar un diccionario con el que iremos contando cada una de las posibilidades. Se verifica palabra por palabra y comentario por comentario el género y número de cada palabra con token.morph y si la palabra tiene género y número, se ñade al diccionario en el índice que le corresponde.\n",
    "\n",
    "Depués se calculan los porcentajes. Con esto teemos los siguientes resultados:\n",
    "\n",
    "Odio:\n",
    "\n",
    "- Masculino singular: 39.82%\n",
    "- Masculino plural: 19.16%\n",
    "- Femenino singular: 32.53%\n",
    "- Femenino plural: 8.49%\n",
    "\n",
    "No odio:\n",
    "- Masculino singular: 41.03%\n",
    "- Masculino plural: 14.97%\n",
    "- Femenino singular: 33.46%\n",
    "- Femenino plural: 10.54%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 9.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio), indica cuántas entidades de cada tipo posible se reconocen en cada uno de los grupos</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de entidades por tipo (grupo odio):\n",
      "PER: 150\n",
      "ORG: 62\n",
      "LOC: 112\n",
      "MISC: 82\n",
      "\n",
      "Cantidad de entidades por tipo (grupo no odio):\n",
      "PER: 48127\n",
      "ORG: 16131\n",
      "LOC: 51921\n",
      "MISC: 12712\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def analyze_entities_by_type(texts, batch_size=50):\n",
    "    # Contador para cada tipo de entidad\n",
    "    entity_counts = {ent_type: 0 for ent_type in [\"PER\", \"ORG\", \"LOC\", \"MISC\"]}\n",
    "    total_entities = 0\n",
    "\n",
    "    # Procesar textos en lotes\n",
    "    for doc in nlp.pipe(texts, batch_size=batch_size, disable=[\"parser\"]):  # Solo análisis de entidades\n",
    "        for ent in doc.ents:\n",
    "            # Validar que la etiqueta de entidad sea válida\n",
    "            if ent.label_ in entity_counts:\n",
    "                entity_counts[ent.label_] += 1\n",
    "                total_entities += 1\n",
    "            else:\n",
    "                print(f\"Etiqueta de entidad desconocida: {ent.label_}\")\n",
    "\n",
    "    # Calcular porcentajes si es necesario\n",
    "    percentages = {k: (v / total_entities) * 100 for k, v in entity_counts.items()} if total_entities > 0 else {}\n",
    "\n",
    "    return entity_counts, percentages\n",
    "\n",
    "# Analizar entidades para cada grupo de comentarios\n",
    "entity_counts_odio, percentages_odio = analyze_entities_by_type(odio['CONTENIDO A ANALIZAR'], batch_size=50)\n",
    "entity_counts_no_odio, percentages_no_odio = analyze_entities_by_type(no_odio['CONTENIDO A ANALIZAR'], batch_size=50)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Cantidad de entidades por tipo (grupo odio):\")\n",
    "for ent_type, count in entity_counts_odio.items():\n",
    "    print(f\"{ent_type}: {count}\")\n",
    "\n",
    "print(\"\\nCantidad de entidades por tipo (grupo no odio):\")\n",
    "for ent_type, count in entity_counts_no_odio.items():\n",
    "    print(f\"{ent_type}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    " \n",
    "Al igual que en el anterior ejercicio, se utiliza el paquete collections para generar un diccionario que contenga el numero de veces que sale cada entidad. \n",
    "\n",
    "Tras ver comentario por comentario viendo que entidades tiene el comentario y contando el numero de entidades distintas que hay en cada grupo, podemos ver los siguientes resultados:\n",
    "\n",
    "Cantidad de entidades (grupo odio):\n",
    "- PER: 150\n",
    "- ORG: 62\n",
    "- LOC: 112\n",
    "- MISC: 82\n",
    "\n",
    "Cantidad de entidades (grupo no odio):\n",
    "- PER: 48127\n",
    "- ORG: 16131\n",
    "- LOC: 51921\n",
    "- MISC: 12712"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 10.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio), extrae y muestra los 100 lemas más repetidos en los comentarios de cada grupo</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 lemas en comentarios de odio:\n",
      "el: 897\n",
      "de: 612\n",
      "que: 548\n",
      "él: 464\n",
      "ser: 375\n",
      "y: 369\n",
      "a: 357\n",
      "uno: 268\n",
      "no: 201\n",
      "en: 189\n",
      "este: 165\n",
      "por: 117\n",
      "haber: 117\n",
      "yo: 105\n",
      "su: 102\n",
      "todo: 101\n",
      "para: 99\n",
      "con: 96\n",
      "como: 94\n",
      "del: 88\n",
      "tener: 75\n",
      "hacer: 75\n",
      "tú: 70\n",
      "más: 69\n",
      "estar: 69\n",
      "si: 67\n",
      "ese: 64\n",
      "puta: 63\n",
      "ir: 63\n",
      "mierda: 59\n",
      "poder: 58\n",
      "al: 55\n",
      "pero: 53\n",
      "dar: 47\n",
      "ya: 44\n",
      "o: 43\n",
      "tanto: 41\n",
      "mucho: 41\n",
      "gobierno: 40\n",
      "panfleto: 38\n",
      "hijo: 38\n",
      "otro: 38\n",
      "decir: 37\n",
      "menudo: 36\n",
      "ni: 36\n",
      "ver: 36\n",
      "españa: 34\n",
      "asco: 33\n",
      "mentiroso: 32\n",
      "qué: 30\n",
      "sin: 30\n",
      "solo: 29\n",
      "país: 28\n",
      "tu: 27\n",
      "q: 26\n",
      "cuando: 25\n",
      "ahora: 24\n",
      "sois: 24\n",
      "gente: 24\n",
      "basura: 23\n",
      "político: 23\n",
      "nuestro: 22\n",
      "nada: 22\n",
      "gentuza: 22\n",
      "bien: 21\n",
      "saber: 19\n",
      "año: 19\n",
      "mundo: 19\n",
      "comunista: 19\n",
      "creer: 18\n",
      "vuestro: 18\n",
      "mismo: 18\n",
      "idiota: 18\n",
      "pues: 18\n",
      "español: 18\n",
      "noticia: 17\n",
      "e: 17\n",
      "sinvergüenza: 17\n",
      "querer: 17\n",
      "poco: 17\n",
      "estupidez: 17\n",
      "gilipol él: 16\n",
      "inútil: 16\n",
      "pagar: 16\n",
      "poner: 16\n",
      "vergüenza: 16\n",
      "porque: 16\n",
      "vaya: 16\n",
      "salir: 15\n",
      "casa: 15\n",
      "siempre: 15\n",
      "pasar: 15\n",
      "vez: 15\n",
      "culo: 15\n",
      "dejar: 15\n",
      "llevar: 14\n",
      "partido: 14\n",
      "votar: 14\n",
      "periódico: 14\n",
      "así: 14\n",
      "\n",
      "Top 100 lemas en comentarios de no odio:\n",
      "el: 421006\n",
      "de: 291568\n",
      "que: 146458\n",
      "en: 126119\n",
      "y: 113710\n",
      "él: 100596\n",
      "a: 96046\n",
      "uno: 92428\n",
      "ser: 66889\n",
      "haber: 64822\n",
      "del: 50343\n",
      "con: 43248\n",
      "por: 42662\n",
      "no: 40220\n",
      "su: 39620\n",
      "para: 35531\n",
      "este: 30213\n",
      "al: 25409\n",
      "más: 20585\n",
      "como: 20524\n",
      "estar: 19169\n",
      "tener: 18457\n",
      "poder: 16306\n",
      "todo: 15679\n",
      "hacer: 14118\n",
      "o: 13433\n",
      "yo: 12978\n",
      "mucho: 12118\n",
      "año: 11943\n",
      "pero: 11896\n",
      "ese: 11609\n",
      "otro: 10339\n",
      "si: 9692\n",
      "ir: 9143\n",
      "ya: 9036\n",
      "también: 8169\n",
      "desde: 7414\n",
      "decir: 7268\n",
      "primero: 7263\n",
      "entre: 7223\n",
      "sin: 7213\n",
      "sobre: 6937\n",
      "día: 6604\n",
      "dar: 6570\n",
      "dos: 6525\n",
      "cuando: 6368\n",
      "gobierno: 6266\n",
      "nuevo: 6211\n",
      "ver: 5965\n",
      "hasta: 5832\n",
      "persona: 5674\n",
      "tanto: 5540\n",
      "país: 5219\n",
      "porque: 5172\n",
      "caso: 5075\n",
      "solo: 5039\n",
      "mismo: 5022\n",
      "españa: 4829\n",
      "parte: 4822\n",
      "último: 4811\n",
      "seguir: 4795\n",
      "tú: 4536\n",
      "así: 4517\n",
      "ahora: 4460\n",
      "llegar: 4407\n",
      "vez: 4379\n",
      "ni: 4363\n",
      "alguno: 4314\n",
      "querer: 4231\n",
      "según: 4227\n",
      "deber: 4158\n",
      "contra: 4121\n",
      "millón: 3996\n",
      "madrid: 3946\n",
      "pasar: 3913\n",
      "donde: 3879\n",
      "tras: 3868\n",
      "durante: 3851\n",
      "nuestro: 3789\n",
      "llevar: 3712\n",
      "después: 3683\n",
      "saber: 3584\n",
      "cada: 3539\n",
      "poner: 3478\n",
      "público: 3444\n",
      "dejar: 3397\n",
      "medio: 3378\n",
      "menos: 3371\n",
      "mes: 3352\n",
      "momento: 3285\n",
      "tres: 3280\n",
      "tiempo: 3265\n",
      "partido: 3252\n",
      "además: 3234\n",
      "qué: 3233\n",
      "español: 3189\n",
      "hora: 3176\n",
      "pasado: 3154\n",
      "bien: 3153\n",
      "euros: 3090\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def obtener_top_lemas(textos, n=100):\n",
    "    # Contador para almacenar lemas\n",
    "    lemas = Counter()\n",
    "\n",
    "    # Procesar textos y extraer lemas\n",
    "    for doc in nlp.pipe(textos, batch_size=50, disable=[\"ner\", \"parser\"]):  # Solo análisis léxico\n",
    "        lemas.update(token.lemma_.lower() for token in doc if not token.is_punct and not token.is_space)\n",
    "\n",
    "    # Retornar los n lemas más comunes\n",
    "    return lemas.most_common(n)\n",
    "\n",
    "# Dividir los grupos de odio y no odio\n",
    "odio = data[data['INTENSIDAD'] > 0.0]\n",
    "no_odio = data[data['INTENSIDAD'] == 0.0]\n",
    "\n",
    "# Obtener los 100 lemas más comunes\n",
    "top_lemas_odio = obtener_top_lemas(odio['CONTENIDO A ANALIZAR'])\n",
    "top_lemas_no_odio = obtener_top_lemas(no_odio['CONTENIDO A ANALIZAR'])\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Top 100 lemas en comentarios de odio:\")\n",
    "for lema, freq in top_lemas_odio:\n",
    "    print(f\"{lema}: {freq}\")\n",
    "\n",
    "print(\"\\nTop 100 lemas en comentarios de no odio:\")\n",
    "for lema, freq in top_lemas_no_odio:\n",
    "    print(f\"{lema}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    " \n",
    "Al igual que en los anteriores ejercicios, usamos collections para guardar en un diccionario el número de veces que sale cada palabra.\n",
    "\n",
    "Viendo comentario por comentario, palabra por palabra y guardando cada palabra en el diccionario,podemos ver en el print las 100 palabras más repetidas cada grupo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 11.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Es posible utilizar alguna de las características extraídas en las preguntas anteriores para determinar si un mensaje contiene odio? Justifica tu respuesta con el análisis estadístico que consideres necesario.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comprobar todos las preguntas para ver si se podría:\n",
    "\n",
    "1.- En esta pregunta solo miramos el número filas del dataset, por lo que no se pueden sacar conclusiones.\n",
    "\n",
    "2.- En esta pregunta solo miramos el número de palabras del corpus, por lo que no se pueden sacar conclusiones.\n",
    "\n",
    "3.- En esta pregunta solo miramos el número medio de palabras por comentario, por lo que no se pueden sacar conclusiones.\n",
    "\n",
    "4.- En esta pregunta podemos ver que en la media los comentarios de odio son mucho más cortos que los comentarios sin odio. Con esto podemos decir que los comentarios de odio se pueden determinar por la longitud, pero esto se debe a que en realidad hay muchos comentarios sin odio que exceden las 1000 palabras y podemos encontrar comentarios sin odio que son muy cortos. Por lo que esto no es un facor diferencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas con más de 1000 palabras: 770\n",
      "                                     CONTENIDO A ANALIZAR  word_count\n",
      "170562  decía paco siempre que él no era nada gallego....        1376\n",
      "428613  si tu niño o niña es absorbente, perseverante ...        1004\n",
      "15900   la ley de presupuestos generales del estado (p...        1182\n",
      "475738  en un mundo profundamente desigual, el reparto...        1885\n",
      "243287  que la operación cataluña existió y que uno de...        1403\n",
      "...                                                   ...         ...\n",
      "54142   aunque para muchas personas el primer contacto...        1135\n",
      "384709  enedina arellano félix, de no ser por los apel...        1185\n",
      "21499   una vitrina en la que lucen siete títulos de l...        1002\n",
      "184694  con la llegada de julio, españa se prepara par...        1178\n",
      "479271  durante décadas, cada madrugada, el capitán ga...        1579\n",
      "\n",
      "[770 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Contar las palabras en \"CONTENIDO A ANALIZAR\"\n",
    "no_odio['word_count'] = no_odio['CONTENIDO A ANALIZAR'].apply(lambda x: len(str(x).split()))\n",
    "# Filtrar las filas con más de 1000 palabras\n",
    "rows_with_many_words = no_odio[no_odio['word_count'] > 1000]\n",
    "# Mostrar el número de filas y sus índices\n",
    "print(f\"Número de filas con más de 1000 palabras: {len(rows_with_many_words)}\")\n",
    "print(rows_with_many_words[['CONTENIDO A ANALIZAR', 'word_count']])\n",
    "\n",
    "no_odio = no_odio.drop(columns=[\"word_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas con menos de 10 palabras: 7308\n",
      "                                     CONTENIDO A ANALIZAR  word_count\n",
      "77315                      pues él también parece sudaca.           5\n",
      "311313  @idiazayuso acuasa a...... da igual cuando lea...           8\n",
      "23904                           carmen calva, la de cabra           5\n",
      "257535                                mal dolor les de...           4\n",
      "302621     @abajolapatria lv no tiene eso de \"seguidores\"           7\n",
      "...                                                   ...         ...\n",
      "404668                desviado en todo esta este gobierno           6\n",
      "282991                     la zorra cuidando el gallinero           5\n",
      "71022             y? saben que les van a tocar los huevos           9\n",
      "86415                                               adéu.           1\n",
      "350884         se está aplanando la curva...dice simón...           6\n",
      "\n",
      "[7308 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Contar las palabras en \"CONTENIDO A ANALIZAR\"\n",
    "no_odio['word_count'] = no_odio['CONTENIDO A ANALIZAR'].apply(lambda x: len(str(x).split()))\n",
    "# Filtrar las filas con menos de 10 palabras\n",
    "rows_with_many_words = no_odio[no_odio['word_count'] <10]\n",
    "# Mostrar el número de filas y sus índices\n",
    "print(f\"Número de filas con menos de 10 palabras: {len(rows_with_many_words)}\")\n",
    "print(rows_with_many_words[['CONTENIDO A ANALIZAR', 'word_count']])\n",
    "\n",
    "no_odio = no_odio.drop(columns=[\"word_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas con menos de 10 palabras: 366\n",
      "                                     CONTENIDO A ANALIZAR  word_count\n",
      "440642                               cuanto gilipollas !!           3\n",
      "192621     los progres siempre predicando con el ejemplo.           7\n",
      "67309                   tienen la a cara como el hormigón           7\n",
      "251781             que tocamiento de huevos más grande...           6\n",
      "485401  jajajaja lo de este panfleto izquierdoso es de...           9\n",
      "...                                                   ...         ...\n",
      "252546             a canarias no vayan. vayanse a italia.           7\n",
      "252003                      otro podemita, otro caradura.           4\n",
      "485619                      la puta tontería de la semana           6\n",
      "251293                         una auténtica hija de puta           5\n",
      "193227  anda pero si está vivo el golfo de @sanchezcas...           9\n",
      "\n",
      "[366 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Contar las palabras en \"CONTENIDO A ANALIZAR\"\n",
    "odio['word_count'] = odio['CONTENIDO A ANALIZAR'].apply(lambda x: len(str(x).split()))\n",
    "# Filtrar las filas con menos de 10 palabras\n",
    "rows_with_many_words = odio[odio['word_count'] <10]\n",
    "# Mostrar el número de filas y sus índices\n",
    "print(f\"Número de filas con menos de 10 palabras: {len(rows_with_many_words)}\")\n",
    "print(rows_with_many_words[['CONTENIDO A ANALIZAR', 'word_count']])\n",
    "\n",
    "odio = odio.drop(columns=[\"word_count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.- Como en el apartado anterior, podemos ver que los comentarios de odio tienen menos oraciones que los comentarios que no tienen odio. Esto se puede deber a que el odio se suele expresar en pocas palabras, pero esto no es un factor diferencial, ya que como podemos ver en el código, el 82% de los comentarios de odio tienen 2 oraciones o menos mientras que el 64% de los comentarios sin odio tienen 2 oraciones o menos. Esto es una diferencia de casi el 20 %, pero no es determinante para validar la teoría de que un comentario con una o dos frases va a ser casi siempre de odio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas con menos de 2 oraciones: 657\n",
      "Número de filas con menos de 2 oraciones: 21757\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Función para contar las oraciones en un texto\n",
    "def contar_oraciones(texto):\n",
    "    if pd.isna(texto):  # Manejar valores nulos\n",
    "        return 0\n",
    "    # Dividir el texto por delimitadores de oraciones y contar\n",
    "    oraciones = re.split(r'[.!?]', str(texto))\n",
    "    return len([oracion for oracion in oraciones if oracion.strip()])\n",
    "\n",
    "# Contar las oraciones en \"CONTENIDO A ANALIZAR\"\n",
    "odio['sentence_count'] = odio['CONTENIDO A ANALIZAR'].apply(contar_oraciones)\n",
    "\n",
    "# Filtrar las filas con menos de 10 oraciones\n",
    "rows_with_few_sentences = odio[odio['sentence_count'] <= 2]\n",
    "\n",
    "# Mostrar el número de filas y sus índices\n",
    "print(f\"Número de filas con menos de 2 oraciones: {len(rows_with_few_sentences)}\")\n",
    "\n",
    "# Eliminar la columna auxiliar\n",
    "odio = odio.drop(columns=[\"sentence_count\"])\n",
    "\n",
    "no_odio['sentence_count'] = no_odio['CONTENIDO A ANALIZAR'].apply(contar_oraciones)\n",
    "\n",
    "# Filtrar las filas con menos de 10 oraciones\n",
    "rows_with_few_sentences = no_odio[no_odio['sentence_count'] <= 2]\n",
    "\n",
    "# Mostrar el número de filas y sus índices\n",
    "print(f\"Número de filas con menos de 2 oraciones: {len(rows_with_few_sentences)}\")\n",
    "\n",
    "# Eliminar la columna auxiliar\n",
    "no_odio = no_odio.drop(columns=[\"sentence_count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.- En este ejercicio podemos ver que hay una diferencia del 20% entre comentarios de odio o no odio que utilizan entidades NER. Pese a esto, casi un 40% de los comentarios de odio usan entidades NER, esto puede ser debido a que la media de palabras por comentario de odio es mucho más baja que en los comentarios de odio, haciendo que sea más baja la posibilidad de usar entidades NER.\n",
    "\n",
    "7.- En este ejercicio, al igual que en el anterior vemos una gran diferencia en el uso de entidades NER de tipo PER, esto se debe a la misma razón que he dado en el ejercicio anterior, por lo que no debería de considerarse como factor determinante para considerar que el comentario es de odio o no según la cantidad de entidades NER de tipo PER.\n",
    "\n",
    "8.- En este ejercicio no vemos muchas diferencias en la cantidad de palabras de diferente genero y número, por lo que no se pueden sacar conclusiones.\n",
    "\n",
    "9.- En este ejercicio no se ven muchas diferencias porcentuales en el uso de diferentes tipos de entidades NER, por lo que no ayuda a sacar conclusiones.\n",
    "\n",
    "10.- Podemos destacar que las palabras con más frecuencia son conectores que no ayudan a distinguir entre comentarios de odio y no odio.\n",
    "\n",
    "En los comentarios también apareces palabras de contexto político y nacional como: gobierno, panfleto, país, político, España y comunista. Estos aparecen en los dos tipos de comentarios, pero según el contexto se podrá diferenciar su tipo de odio.\n",
    "\n",
    "Por último, se puede observar que aparecen palabras con contexto negativo como: puta, mierda, asco, mentiroso, basura, gentuza, idiota, sinvergüenza, estupidez, gilipollas, inútil, vergüenza, y culo. Las cuales no aparecen el los comentarios sin odio, por lo que esto podría ser una pista para comprobar el odio.\n",
    "\n",
    "En esta partición del dataset hay 789 comentarios de odio y 34211 de no odio por lo que tendremos que ver la frecuencia relativa con la que salen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frecuencias en comentarios de odio:\n",
      "gobierno: 32,  4.0558%\n",
      "panfleto: 27,  3.4221%\n",
      "país: 15,  1.9011%\n",
      "político: 1,  0.1267%\n",
      "comunista: 5,  0.6337%\n",
      "\n",
      "Frecuencias en comentarios de no odio:\n",
      "gobierno: 4954, 14.4807%\n",
      "panfleto: 19, 0.0555%\n",
      "país: 2540, 7.4245%\n",
      "político: 517, 1.5112%\n",
      "comunista: 137, 0.4005%\n"
     ]
    }
   ],
   "source": [
    "palabras_políticas = [\n",
    "    \"gobierno\", \"panfleto\", \"país\", \"político\", \"comunista\"\n",
    "]\n",
    "\n",
    "# Función para contar las palabras emocionales en un DataFrame\n",
    "def contar_palabras(df, columna_texto):\n",
    "    # Crear un diccionario para almacenar las frecuencias\n",
    "    frecuencias = {palabra: 0 for palabra in palabras_políticas}\n",
    "\n",
    "    # Iterar sobre las filas del DataFrame\n",
    "    for texto in df[columna_texto]:\n",
    "        if pd.isna(texto):  # Ignorar valores nulos\n",
    "            continue\n",
    "        texto = texto.lower()  # Convertir texto a minúsculas\n",
    "        for palabra in palabras_políticas:\n",
    "            frecuencias[palabra] += texto.split().count(palabra)\n",
    "\n",
    "    return frecuencias\n",
    "\n",
    "\n",
    "# Contar palabras emocionales en ambos DataFrames\n",
    "frecuencias_odio = contar_palabras(odio, \"CONTENIDO A ANALIZAR\")\n",
    "frecuencias_no_odio = contar_palabras(no_odio, \"CONTENIDO A ANALIZAR\")\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Frecuencias en comentarios de odio:\")\n",
    "for palabra, frecuencia in frecuencias_odio.items():\n",
    "    print(f\"{palabra}: {frecuencia},  {round((frecuencia/789)*100, 4)}%\")\n",
    "\n",
    "print(\"\\nFrecuencias en comentarios de no odio:\")\n",
    "for palabra, frecuencia in frecuencias_no_odio.items():\n",
    "    print(f\"{palabra}: {frecuencia}, {round((frecuencia/34211)*100, 4)}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frecuencias en comentarios de odio:\n",
      "puta: 44,  5.5767%\n",
      "mierda: 46,  5.8302%\n",
      "asco: 30,  3.8023%\n",
      "mentiroso: 16,  2.0279%\n",
      "basura: 12,  1.5209%\n",
      "gentuza: 17,  2.1546%\n",
      "idiota: 5,  0.6337%\n",
      "sinvergüenza: 6,  0.7605%\n",
      "estupidez: 12,  1.5209%\n",
      "gilipollas: 14,  1.7744%\n",
      "inútil: 4,  0.507%\n",
      "vergüenza: 9,  1.1407%\n",
      "culo: 8,  1.0139%\n",
      "\n",
      "Frecuencias en comentarios de no odio:\n",
      "puta: 72, 0.2105%\n",
      "mierda: 118, 0.3449%\n",
      "asco: 59, 0.1725%\n",
      "mentiroso: 18, 0.0526%\n",
      "basura: 152, 0.4443%\n",
      "gentuza: 36, 0.1052%\n",
      "idiota: 12, 0.0351%\n",
      "sinvergüenza: 17, 0.0497%\n",
      "estupidez: 30, 0.0877%\n",
      "gilipollas: 26, 0.076%\n",
      "inútil: 54, 0.1578%\n",
      "vergüenza: 236, 0.6898%\n",
      "culo: 47, 0.1374%\n"
     ]
    }
   ],
   "source": [
    "palabras_emocionales = [\n",
    "    \"puta\", \"mierda\", \"asco\", \"mentiroso\", \"basura\", \"gentuza\", \"idiota\", \n",
    "    \"sinvergüenza\", \"estupidez\", \"gilipollas\", \"inútil\", \"vergüenza\", \"culo\"\n",
    "]\n",
    "\n",
    "# Función para contar las palabras emocionales en un DataFrame\n",
    "def contar_palabras(df, columna_texto):\n",
    "    # Crear un diccionario para almacenar las frecuencias\n",
    "    frecuencias = {palabra: 0 for palabra in palabras_emocionales}\n",
    "\n",
    "    # Iterar sobre las filas del DataFrame\n",
    "    for texto in df[columna_texto]:\n",
    "        if pd.isna(texto):  # Ignorar valores nulos\n",
    "            continue\n",
    "        texto = texto.lower()  # Convertir texto a minúsculas\n",
    "        for palabra in palabras_emocionales:\n",
    "            frecuencias[palabra] += texto.split().count(palabra)\n",
    "\n",
    "    return frecuencias\n",
    "\n",
    "\n",
    "# Contar palabras emocionales en ambos DataFrames\n",
    "frecuencias_odio = contar_palabras(odio, \"CONTENIDO A ANALIZAR\")\n",
    "frecuencias_no_odio = contar_palabras(no_odio, \"CONTENIDO A ANALIZAR\")\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Frecuencias en comentarios de odio:\")\n",
    "for palabra, frecuencia in frecuencias_odio.items():\n",
    "    print(f\"{palabra}: {frecuencia},  {round((frecuencia/789)*100, 4)}%\")\n",
    "\n",
    "print(\"\\nFrecuencias en comentarios de no odio:\")\n",
    "for palabra, frecuencia in frecuencias_no_odio.items():\n",
    "    print(f\"{palabra}: {frecuencia}, {round((frecuencia/34211)*100, 4)}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver los porcentajes indican un gran indicio de que en los comentarios de odio aparecen más estas palabras, aunque sigue dependiendo del contexto, ya que aparecene en los comentarios sin odio. \n",
    "\n",
    "Esto puede no tener mucho sentido ya que las palabras \"idiota\" o \"gilipollas\" no se pueden llegar a usar facilmente en comentarios sin odio, por lo que podemos pensar que los datos no han sido etiquetados correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comentarios de no odio que contienen la palabra 'gilipollas':\n",
      "jajajaja esta semana lo estais bordando, quien os hace las noticias? primero los nose cuentos muertos de una familia en un lugar perdido de méxico por ir a un funeral y ahora los infectados por la fiesta de un cumpleaños de un gato en chile, cada vez nos toman más x gilipollas\n",
      "------------------------------------\n",
      "multa a la discoteca mínimo con 6 ceros, multa a todos los asistentes mínimo con 3 ceros y así nos ahorraríamos a los gilipollas y la subida de los impuestos!\n",
      "------------------------------------\n",
      "la humanidad se extingue.... por gilipollas. punto\n",
      "------------------------------------\n",
      "la gente es gilipollas. no se puede reciclar con tanto montón de basuras, es lógico.\n",
      "------------------------------------\n",
      "el sentido común, decía descartes, es la cosa mejor distribuida del mundo, pues nadie apetece más del que tiene, aunque en la práctica pocos lo defienden. hay cierta coincidencia en que el conocimiento científico exige métodos más precisos. pero incluso la ciencia da por supuestas ciertas dosis de sensatez, así que no debiera extrañar que, de pronto, varios libros hablen de ese sentido y lo reivindiquen.javier vilanova ha titulado su último libro filosofía de sentido común; su publicación coincide con la versión española de la red de la creencia, de w. v. quine y j. s. ullian. el sentido común y la preferencia por el lenguaje ordinario son la base de filosofía ante el desánimo, de josé carlos ruiz; el mundo desde dentro, de carlos nieto blanco, es un estudio sobre josé ferrater mora, que unió su voluntad analítica a amplias dosis de eso que los catalanes llaman seny (sensatez). por caminos diferentes discurre la obra de hermann keyserling (estonia, 1880- austria, 1948) quien decidió recorrer el mundo para ver dentro de sí mismo. la experiencia se plasmó en diario de viaje de un filósofo, que tradujo hace un siglo manuel garcía morente y ahora se reedita.la red de la creencia es un texto de divulgación en el que se exponen con claridad los elementos centrales de la filosofía de la ciencia y del lenguaje, dominantes en la segunda mitad del siglo xx y en vigor aún. para quine ―figura relevante de esta tendencia― y ullian la ciencia es fruto de la investigación racional, de ahí que tenga enemigos notables entre los partidarios de doctrinas irracionales. el libro distingue entre las creencias razonables y las que no lo son y analiza los instrumentos intelectuales que permiten distinguir unas de otras. la base de las creencias son los sentidos y el lenguaje, una institución social que multiplica nuestra capacidad de observación al permitirnos el acceso a las observaciones de los demás. no obstante, resulta imprescindible saber cuándo los testimonios (los ajenos y los de los propios sentidos) son de fiar.en el camino, se analizan las creencias autoevidentes, el papel de los axiomas, las inferencias, las implicaciones y los sistemas explicativos causales y teleológicos. las creencias son útiles, la credulidad no lo es tanto. será bueno abandonar una creencia cuando no se hallen evidencias que la avalen, avales que deben responder a criterios intersubjetivos porque “nadie corroboraría la información de un periódico examinando más copias del mismo periódico”.probablemente los autores desconocían la máxima orteguiana que afirma que la claridad es la cortesía del filósofo (sí la conoce, y la cita, josé carlos ruiz), pero comparten la idea. “es una máxima básica para el pensamiento serio que sea lo que sea lo que hay que decir, se puede decir con perseverancia de forma clara”.en varios puntos enlaza javier vilanova con quine y ullian. uno es la defensa del lenguaje común, ya que “el lenguaje es el gran depositario de los resultados acumulados por la actividad humana”. en los primeros capítulos el autor procede a una especie de eliminación de prejuicios, para luego abordar qué pueda ser ese sentido común, a través de la historia de la filosofía hasta llegar al presente: “en pocos momentos de su historia”, sostiene, “viaja la filosofía tan de espaldas al sentido común”, lo que le lleva a plantear la función del lenguaje, muy de la mano de austin y wittgenstein, y no lejos de quine para quien a veces no se trata tanto de resolver un problema filosófico como de disolverlo mediante el análisis lingüístico. pero el objetivo de la filosofía no se agota en el sentido de las palabras. sostiene vilanova que “el filósofo es el que conoce el sentido de la vida”, aunque no todos los filósofos persigan ese fin hoy, cuando “la filosofía sigue en su deriva hacia la ultraespecialización y el academicismo” dejando de lado “una de las funciones más tradicionales del filosofar: la clarificación”. de ahí que la claridad haya sido “una de las más grandes aspiraciones del filósofo, si no la más grande”. en el presente “no sólo es cada vez más difícil para un filósofo entender a otro filósofo”, lo malo “es que cada vez se hace más difícil, si no se ha hecho ya imposible, entender al filósofo para la persona que no es filósofo”. así que “poner en contacto los problemas reales con los problemas filosóficos vincula el sentido común a la reflexión filosófica y, ya de paso, al filósofo con el sentido común de los hombres”.hay en el libro muchos comentarios supuestamente jocosos. una de esas bromas confunde la provocación con la impertinencia. en la página 121 vilanova se permite llamar “gilipollas” al lector. una invitación a abandonar la lectura.el gusto por la claridad y un cierto sentido común es patente en filosofía ante el desánimo. que es un libro de filosofía queda claro a partir de las referencias que emplea el autor. pero no es una obra filosófica en sentido fuerte. algunos de los temas principales de la reflexión filosófica (teoría del conocimiento, ontología, metafísica) quedan al margen o son meros elementos referenciales. en su lugar, el autor se pasea por los rincones filosóficos. aborda la identidad, en un sentido muy distinto al de los lógicos e incluso al de hume; analiza relaciones intersubjetivas como el amor o la amistad, y nociones subjetivas como la percepción de la edad, el dolor o el placer. incluso cuando habla del pensamiento, parece más centrado en cómo se da que en el hecho mismo de pensar. se trata de un libro interdisciplinar, que, desde la filosofía, cruza terrenos de la antropología, la sociología, la psicología e incluso los manuales de autoayuda.domina en la obra el estoicismo, con concesiones a un epicuro alejado de cualquier tipo de hedonismo. el libro es un intento de comprender el presente. un presente rabioso que, a veces, zigzaguea. así, ruiz explica que la pandemia ha disparado los divorcios. el dato era exacto cuando fue escrito pero en los últimos meses los divorcios han caído, por motivos económicos fundamentalmente, según los sociólogos. destaca la reflexión sobre la ignorancia del hombre actual (“existe una idea común que defiende que estamos potenciando una sociedad de idiotas y también de imbéciles”, dice), que bebe del divertido panfleto de carlo m. cipolla allegro ma non troppo, las leyes fundamentales de la estupidez humana. la idiotez es individual, pero se acentúa en la masa. a partir de ahí, establece ruiz la hipótesis de si hay relación entre la estupidez y la maldad y cómo este asunto deviene crucial cuando se trata de comportamientos relativos a los asuntos públicos, protagonizados por personajes públicos. sobran los ejemplos.las tres obras citadas buscan orientar al lector en el campo de la filosofía o de la vida. el libro de carlos nieto blanco, sin desdeñar la visión global, recorre la trayectoria de ferrater mora, en paralelo al pensamiento del siglo xx que tan bien cultivó y divulgó ferrater. nieto blanco no obvia el diccionario filosófico, pero destaca que el filósofo no se agota en la tarea que le dio más fama.ferrater fue también un amante del sentido común y de la claridad. su obra evidencia su enciclopedismo y una voluntad universalista. busca en los autores lo más interesante en vez de enfatizar la disidencia. fue, dice nieto blanco, “un constructor de puentes y no un hacedor de abismos”.se describe también al ferrater divulgador de la lógica y de la filosofía del lenguaje y al periodista, fotógrafo y cineasta, con referencias a la correspondencia del autor. uno de sus amigos, tan dispar, fue joan oliver (pere quart), quien escribió: “ferrater mora es un filósofo que ama el lenguaje casi tanto como un poeta”, aspecto especialmente relevante porque “en filosofía el asunto del que se trata es el pensamiento; el estilo literario debe confinarse a la expresión y modulación de los pensamientos. actualmente no hay ninguna razón para que el lenguaje no deba combinar la precisión con la belleza. cuando ello sucede obtenemos la transparencia y la claridad que son características de la prosa de ferrater mora”.el volumen incluye una cuidada bibliografía, un prólogo de victoria camps y un texto de javier muguerza a modo de epílogo.hermann keyserling fue un noble estonio buen conocedor de la filosofía de su tiempo. decidido a confrontarse con el todo como vía para llegar al conocimiento de sí mismo, emprendió una vuelta al mundo que le llevó a asia a través de suez. realizó prolongadas estancias en india, china y japón visitando sus centros de pensamiento, antes de iniciar el retorno por estados unidos. en todas partes intenta comprender el modo de pensar y sentir del otro, para ver si logra asir una realidad que, de una u otra forma, cree que se le escapa. su interés es universal: la naturaleza, el arte, el sentido de la historia, la moral, la política, incluyendo las diversas variantes de la religión que encuentra en su camino. sugiere que, tal vez, percibir desde el ser o el devenir no son otra cosa que “distintos aspectos de una realidad absolutamente idéntica”. puntos de referencia para entenderlo serían hegel y bergson, si bien este último, lamenta keyserling, “todavía no ha tocado el mundo del deber”.para keyserling es kant un referente constante, incluso para explicar sus sensaciones ante la visión del cañón del colorado donde aprecia la concepción kantiana de “lo sublime”.a su vuelta tuvo que aplazar la publicación debido a la primera gran guerra. “fuera ruge la guerra mundial”, escribió, “no es bastante que todos aspiren a aniquilarse: por boca de sus directores espirituales se calumnian y se injurian unos a otros, desmedidamente, como los héroes homéricos. toda armonía, toda comprensión, está en suspenso. la unidad de la humanidad parece no existir”. eso era hace cien años. hora más, hora menos.puedes seguir a babelia en facebook y twitter, o apuntarte aquí para recibir nuestra newsletter semanal.\n",
      "------------------------------------\n",
      "pero si sois gilipollas como voy a pagaros\n",
      "------------------------------------\n",
      "y habrá gilipollas que acudan, sabiendo que protestan contra quien les da de comer, y coloca a sus allegados.\n",
      "el espectáculo debe continuar!!!\n",
      "qué no decaiga!!!\n",
      "------------------------------------\n",
      "más gilipollas quién lo compre.\n",
      "------------------------------------\n",
      "en el gobierno no hay ni uno solo que se salve de ser gilipollas.\n",
      "------------------------------------\n",
      "menos mal. era algo imprescindible para la cura del cáncer, del vih, o para resolver el hambre en áfrica. \n",
      "\n",
      "ahora podemos estar tranquilos!!!\n",
      "\n",
      "hace falta ser gilipollas.\n",
      "------------------------------------\n",
      "@teresasv entendemos perfectamente que más de un 60% de la factura son impuestos. poned dibujos que pongan: mirad gilipollas pagáis muchos impuestos en la factura. a ver si alguno se entera.\n",
      "------------------------------------\n",
      "qué pena no se hubieran congelado todos estos sinvergüenzaas gilipollas.\n",
      "------------------------------------\n",
      "hace cinco años, alejandro palomo (posadas, córdoba, 29 años) pensó que faltaba en el mundo de la moda una marca que permitiese a los hombres vestirse con ropajes habitualmente asignados a las mujeres. la idea parecía una locura pero era tan buena que sus propuestas han seducido desde a anna wintour, la gran dama de la moda global hasta a beyoncé, quien eligió una de sus prendas para presentar al mundo a sus mellizos en una foto inolvidable. la pasada semana presentó su décima colección en un multitudinario desfile en el paseo del prado, de madrid, al que acudió, entre otros, el alcalde de la capital, josé luis martínez-almeida, quien asistió asombrado al despliegue de ambigüedad de los palomos, esa troupe sofisticadísima y muy joven que siempre rodea al diseñador: “al final hemos conseguido que haya gente que viva esta ropa de una forma totalmente natural”.pregunta. cinco años después de empezar, ¿a qué sigue teniéndole miedo?respuesta. a quedarme obsoleto y antiguo y hacer algo que no sea relevante para la sociedad. por eso siempre me mantengo cerca de las generaciones jóvenes, porque me aportan esa frescura. cuando era niño me juntaba en los recreos con los profesores y ahora que puedo ser el profesor, pues me junto con los niños, a ver qué me cuentan.p. ¿y mantiene contacto con esos profesores del colegio?r. cuento mucho con mi profesor de historia del arte, josé antonio pérez guillén, que fue uno de mis grandes descubridores. siempre que vamos a meterle mano a alguna corriente artística contamos con él para clases magistrales. te enamora escucharle, es una maravilla.p. ¿durante el confinamiento llegó a plantearse a qué se iba a dedicar si hubiese tenido que reciclarse totalmente?r. desde luego que sí, que estuve asustadísimo y pensando qué íbamos a hacer con nuestra vida. pero enseguida intentamos entender qué es lo que teníamos que hacer para adaptarnos a la nueva era: pasar de estar pendiente de lo que dice la prensa de ti en cada momento y mirar solo al cliente, que en ese momento necesitaba pijamas. pues fue lo que hicimos. pijamas de seda.p. ¿quién era la persona que más le imponía del mundo de la moda cuando empezó?r. cuando empecé y a día de hoy, anna wintour. te encuentras con ella, te hace un par de preguntas y ya te tiemblan las piernas. te pregunta: ¿cómo es tu negocio? ¿cómo lo vas a desarrollar? se te corta la voz y después piensas, dios, podía haber dicho esto o lo otro, soy gilipollas.p. esto fuera, ¿en españa quién le daba mucho miedo?r. pues posiblemente mi madre. si hubiera sido por ella igual no hubiera empezado con la marca porque tenía un miedo tremendo. en cuanto terminé de estudiar, ella me buscaba entrevistas en inditex y en bimba y lola, que es lo que la hubiera dejado tranquila. pero yo hice lo que me dio la gana.p. ¿y quién le apoyó?r. mi padre, que es un soñador como yo. mi madre desde luego es la que más razón lleva, pero es él quien se ha creído esta historia conmigo.p. ¿por qué cree que en su casa han sido tan abiertos de mente?r. mis padres, aunque sean de pueblo, han sido los más modernos. cuando se dieron cuenta de que yo era un niño diferente lo cogieron e hicieron lo máximo de eso. si a mí me gustaba pintar, mi padre, al día siguiente me traía un caballete, un estuche de óleos o me apuntaba a pintura. y luego con el tema de la sexualidad, cuando yo era niño, que siempre estás confundido y no sabes muy bien, yo igual decía: “bueno, cuando tenga novia”. y mi madre: “bueno, cuando tengas novia ¡o novio!”.p. ¿qué le pareció que el alcalde de madrid fuese al desfile?r. pues muy bien. es muy importante que vaya a todas las iniciativas que se hagan y más esta, donde el apoyo del ayuntamiento ha sido fundamental [la música del desfile, compuesta específicamente para la ocasión, la puso la orquesta sinfónica municipal, que tocó en directo]. además quería darle un beso a andrea [levy], que se ha portado fenomenal con nosotros.p. el otro día circuló mucho una foto del desfile en la que almeida evita mirar unos pantalones con una especie de solapa trasera que cuando se abre dejan ver las nalgasr. lo creas o no son el producto que más hemos vendido en la historia de palomo. cada vez que hay una reposición hay una cola de 60 personas para comprarlo. sienta fenomenal y luego no tiene por qué tener ese uso explícito que te imaginas pero sí ese guiño. nació en una colección inspirada en la caza, donde los pantalones se abren por delante, como los de los marineros.p. vive usted en posadas, el pequeño pueblo de córdoba donde nació y tiene su taller. ¿les miran como bichos raros cuando andan por ahí?r. a posadas ha venido desde almodóvar hasta gente del mundo de la moda de parís y es un sitio donde todo el mundo es bienvenido. estamos todos perfectamente integrados. tanto que hasta a mí mismo me resulta extraño. el otro día vi a un chico con un vestido en la cola del súper y pensé: “¿quién coño es ese?” ¡y resulta que era uno de los míos! [risas]p. ¿está usted a gusto en madrid? ¿ve la ciudad muy crispada?r. sé que se han vivido momentos de mucha crispación, pero la realidad que yo vivo en madrid es totalmente diferente. siento una libertad absoluta y te contagias de una energía tan acogedora en cuanto llegas, es alucinante. tiene tanto de ciudad y tanto de pueblo… me apasiona, de verdad.p. ¿nota más homofobia en las calles cuando viene a madrid?r. la verdad es que tengo que decir que la única vez que me han gritado algo por la calle ha sido hace dos semanas. yo iba con mi chico volviendo a casa por la noche y nos gritaron maricones e hijos de puta. fue muy fuerte. a mi chico, que es un poco ajeno a todo esto, le dije: “¿te das cuenta de que nos están lanzando gritos homófobos?”.p. ¿y fue duro ese momento?r. nuestra primera reacción fue soltarnos de la mano. pero bueno, intentas que no sea lo principal en tu vida. nosotros hemos creado una familia de gente que nos hace sentir a gusto. hay quien tiene mucho miedo al avance y al futuro y no sé por qué hay cromañones que siguen con ideas tan rancias, cuando es muy fácil que vivamos de forma bonita y pacífica. que cada uno haga lo suyo y lo que haga el de al lado, ¿a ti qué coño te importa?p. ¿le cansa que le pregunten si su ropa es más masculina o más femenina y si se la tiene que poner un hombre o una mujer?r. ese debate estuvo superado desde el principio. nosotros nunca hicimos nada con una intención reivindicativa, aunque me gusta que la marca también tenga esa connotación medio política. no pretendo que todo mundo vaya vestido con mi ropa. yo lo que digo siempre es que palomo le da la libertad absoluta al hombre para hacer lo que le dé la gana.\n",
      "------------------------------------\n",
      "que falso, ni que fuéramos gilipollas, con lo bien que se está sin tener que pagar a bruselas\n",
      "------------------------------------\n",
      "un enfermero del hospital 12 de octubre, que el pasado jueves fue brutalmente golpeado por un joven en el metro de madrid, ha perdido la visión del ojo. \"es difícil que vuelva a ver con él\", apuntan fuentes sanitarias a este diario.la agresión se llevó a cabo \"con un objeto punzante\", según fuentes policiales, ante la mirada atónita del resto de pasajeros. el golpe seco en el ojo derecho de la víctima la dejó noqueada por momentos, teniendo que apoyar una rodilla en el suelo al perder el equilibrio tras el impacto. nadie detuvo al agresor, que abandonó el vagón en la estación alto del arenal espetándole al herido: \"gilipollas, ojalá te mueras\".el asaltante, que exhibió una actitud provocadora y desafiante, aún no ha sido identificado. en las imágenes se aprecia cómo es la única persona en el vagón que no llevaba puesta la mascarilla. según las primeras hipótesis, ésta sería la razón por la cual se habría originado el careo antes de la agresión.el enfermero tuvo que ser ingresado en el hospital 12 de octubre, donde continúa recuperándose. el sindicato policial ufp ha pedido colaboración ciudadana para obtener alguna pista que permita detener al autor de los hechos.las reacciones en las redes sociales no se han hecho esperar. tras hacerse público el vídeo, decenas de internautas indignados clamaban justicia ante semejante acto, deseando que pronto sea atrapado el agresor.\n",
      "------------------------------------\n",
      "ser taurina es una opción, ser gilipollas no.\n",
      "------------------------------------\n",
      "jajajajaja gilipollas. el presidente, amigos, es trump que yo sepa. para impeachment no hay tiempo. y esa fulana no puede dar órdenes al pentágono.\n",
      "------------------------------------\n",
      "a ti si que te gusta tomarnos por gilipollas,fenomeno\n",
      "------------------------------------\n",
      "en serio , sois gilipollas o ya nacisteis así ???\n",
      "------------------------------------\n",
      "yo pienso que algunos nacen gilipollas y después se hacen de izquierdas , como proceso natural.\n",
      "------------------------------------\n",
      "¿un remedio? ¿al ciclo menstrual gracias al cual el ser humano se reproduce? ¿sois gilipollas? #lopaís\n",
      "------------------------------------\n",
      "nunca vi tantos gilipollas juntos, inconscientes, descerebrados, los mandaría a los hospitales a realizar las tareas mas desagradables y a los cementerios para que vean la verdad de esta pandemia, por ahí recuperan la poca conciencia que tienen y lo hago extensivo a sus padres,\n",
      "------------------------------------\n",
      "el servicio público frente al dinero...sí, es un caso claro de gilipollas nivel dios\n",
      "------------------------------------\n",
      "nos toman por gilipollas estos políticos. sabemos que todo es un paripe para ganar votos.\n",
      "------------------------------------\n",
      "pues que le vean los de andorra. más gilipollas será el que le siga y pague religiosamente sus impuestos aquí.\n",
      "------------------------------------\n",
      "cada dia estamos mas gilipollas\n",
      "------------------------------------\n",
      "lo que se conoce vulgarmente como un gilipollas, pero famoso, para entendernos.\n",
      "------------------------------------\n",
      "solo un gilipollas cree que quien le desprecia le va a aplaudir cuando ya le ha sacado lo que quería.\n",
      "------------------------------------\n",
      "y dentro de dos semanas dirá que tenemos un 85% de casos de variante británica ... y así todo... creo que ya nos toma por gilipollas.\n",
      "------------------------------------\n",
      "“¿me van a dejar terminar?”. “¿puedo hablar?” “¿puedo hacer mi trabajo?”. los espectadores de la primera temporada de hierro (movistar +) ya entendieron que la paciencia y estoicismo de la jueza candela montes (interpretada por candela peña) siempre será proporcional a la cantidad de veces que los hombres intentarán interrumpirla. ese confort por lo aprendido, ese déjà vu que en lenguaje de internet se reduce al repetitivo, sonoro y potente “¡dilo!”, nos invade de nuevo en la segunda temporada que se estrenó el pasado viernes. aliviados y entrenados, como ese bienestar que proporciona meterse en esas sábanas que ya conocemos del hogar parental, brindamos (no tan figuradamente) con nuestra pantalla cada vez que su señoría manda callar a los mansplainers sin que le tiemble su siempre impecable y aspiracional flequillo.con dos episodios emitidos hasta esta fecha –los próximos se colgarán cada viernes de forma semanal–, la segunda temporada de hierro, el proyecto creado por pepe coira y alfonso blanco y dirigido por jorge coira, certifican que esta ficción ambientada en la isla más remota de las canarias es capaz de superarse a sí misma. que este drama negro ni pierde fuelle ni defrauda tras resolver el misterio de quién mató a fran, la trama que movió el interés de la temporada inicial. por una parte, la nueva etapa sigue conectada con varios personajes y funciona como una especie de epílogo de lo ocurrido. ahí están, enormes, díaz (dario grandinettti) y su hija pilar (kimberley tell), lidiando desde su platanera con los chanchullos no resueltos de narcotráfico con el heterodoxo a la par que fascinante y lynchiano clan familiar de samir (el personaje de antonia san juan siempre estará presente, como ese retrato imponente que preside en ese enigmático salón de su hogar colonial). por otra, la temporada introduce a nuevos personajes que conectan a todos entre sí. gaspar varela (matías varela), un ambicioso especulador mafioso fanático de la camisa y americana prieta a lo santiago abascal, enfrentándose a la custodia de sus hijas –ágata (naira lleó) y dácil (helena sempere)– con su ex pareja, lucía (aroha fahez) en un conflicto que dividirá a la isla en dos bandos.sin perder ese halo de magnetismo hacia lo sublime y sobrecogedor de una isla que se erige como una protagonista más, el terreno traza paralelismos visuales con la trama entre los planos colosales y magnéticos de la naturaleza más brutal e imprevisible. lidiando con esas brumas de altura embutida en power suits y faldas lápiz y sin renunciar a sus tacones para encaramarse a calles empedradas, hierro corona de nuevo a la jueza montes, merecidísimo triunfo para candela peña en los premios feroz y de la unión de actores de 2020, en ese endiosado equipo de mujeres carismáticas y decididas de la televisión–eso para los que tengan buen ojo; para los de tradición misógina serán bordes y estiradas–. una liga en la que también juegan con soltura la abogada diane lockhart de the good fight, la inspectora laia urquijo de antidisturbios o la detective stella gibson de the fall. en hierro, esa jueza implacable que ha acabado castigada en una isla lo más alejada de la península por cuestionar demasiadas cosas, también es una madre coraje y una mujer vulnerable y afectada por la culpa de sus nada fáciles decisiones.en la primera temporada un lugareño le explica a la jueza que el asesinado era un poco “machango”, lo que según la jerga local es “un tipo cojonudo, pero un poco gilipollas”. en tiempos en los que a muchos nos gustaría tener esa firmeza para gritar ese “¿puedo hablar?” entre tanto ruido ambiental, es ver a esa jueza “acostumbrada a los problemas” reclamar sensatamente su lugar y el espectador pandémico no puede evitar suspirar y pensar cuánta falta hace nos hace una candela montes para pedir sitio y para callar, de una vez por todas, a todos los machangos con los que lidiar.\n",
      "------------------------------------\n",
      "esta comparando el exilio de los negrin y compañia, que robaron hasta las monedad del museo arqueológico y se fueron forrados, como el delincuente fugado puigdemont que vive a cuerpo de rey donde perdió napoleón. este tio es gilipollas pero pa siempre.\n",
      "------------------------------------\n",
      "paco lucena se ha acercado esta mañana al banco y ha comprobado que no tiene dinero. cero. es 22 de junio y cobra la pensión de autónomo, 680 euros, los 24 de cada mes. saca un pequeño monedero, abre la cremallera y se lo muestra al periodista. “mira, esto es todo [unas cuantas monedas de céntimos]. el poderoso mánager paco lucena no tiene ni tres euros”, ironiza. está en su casa, un piso vetusto de 70 metros cuadrados en las profundidades del barrio de aluche, en el sur de madrid. las persianas permanecen medio bajadas y las cortinas extendidas. son las doce de la mañana, ahí fuera luce el sol, pero en esa casa abigarrada reinan las sombras.la cama está sin hacer y las paredes, pobladas de fotografías. en muchas se ve el cuerpo enjuto de joaquín sabina, al que lucena representó durante 22 años, desde que comenzó, en 1978, hasta 2000, en plena gira del disco 19 días y 500 noches. también cuelgan imágenes de silvio rodríguez, andrés calamaro, manolo tena, coque malla, chavela vargas, luis eduardo aute, miguel ríos… figuras políticas como fidel castro, dolores ibárruri, juan barranco… todos posan con lucena, ese que un día fue uno de los representantes musicales más poderosos de españa y hoy malvive solo, sin apenas recursos, ignorado por los que un día él ayudó a encumbrar.el hombre que solía desayunar, comer y cenar con moët & chandon sorbe hoy un nestea. aquel que comió con pepe mujica, cenó con gabriel garcía márquez y fue recibido “tres veces” por fidel castro no tiene con quien hablar. suena mozart desde su ordenador de mesa. “qué belleza”, dice. respira pesadamente y suelta algún “ay” de dolor en la espalda cuando se mueve para mostrar fotos del pasado.lucena (tánger, 68 años) lleva prácticamente 11 años sin salir de casa. se acerca al ahorra más del barrio, compra y de vuelta a casa ayudado por un bastón. hace dos años, justo antes de la pandemia, la falta de una alimentación adecuada y las pastillas que le ayudan a dormir le provocaron un desmayo. cayó en el salón a plomo. el sonido alertó a su vecina, fanny, que acudió al rescate. el golpe le afectó a su ya maltrecho costado derecho. también se rompió los dientes. estuvo toda la pandemia sin ellos. “hace dos semanas por fin me los han terminado de poner, porque no podía ni comer ni hablar bien. vicente, el marido de mi mejor amiga, isabel, me llamó un día y me dijo: ‘paco, sé que tienes problemas para comer porque no tienes dientes. vamos a pedir presupuesto’. lo ha pagado todo él, 12.000 euros”. sobre cómo ha acabado así un hombre que llegó a tener a 60 artistas en su empresa de representantes es de lo que trata esta historia.lucena se hizo representante por azar. llegó a madrid procedente de tánger, donde nació, a principios de los setenta. de creencias marxistas, ingresó en las juventudes comunistas y con el tiempo formó parte del comité central de un partido comunista de españa que caminaba con pies de plomo tras la muerte de franco. a finales de los años setenta se ocupó de la seguridad de dolores ibárruri. el partido alquiló a la pasionaria un piso de la vaguada (zona norte de madrid) y lucena vivió con ella seis meses. su misión era cuidarla: además de protegerla de posibles agresiones (franco había muerto, pero no el franquismo), hacía la compra o le leía la prensa. “una de las personas más maravillosas que he conocido”, recuerda.en 1978 conoció en los “bares de rojos” de madrid a joaquín sabina, que acababa de llegar de un exilio londinense de siete años. el músico estaba a punto de editar su primer disco, inventario (1978). sabina encontró a un alma gemela en lucena: se identificaban políticamente, leían a los mismos escritores y les apasionaban silvio rodríguez y bob dylan. solo había una diferencia: uno era músico y el otro daba clases de francés en una escuela de idiomas. son los tiempos de la mandrágora. lucena empieza a acompañar a javier krahe y a sabina a los conciertos que les van saliendo (no demasiados) y a organizar aquí y allá. gracias a que domina el francés le sale un trabajo de administrativo en países donde se habla esa lengua, como guinea conakry y costa de marfil. en 1980 regresa a madrid con algo de dinero y decide montar una empresa de representación de artistas. “yo no era un manager ni tenía ni idea. pero joaquín [siempre se refiere a sabina por el nombre de pila] me persiguió durante dos años para que le llevase la carrera”, informa. y aceptó.lucena estrena una profesión que en españa está por construir. se mueve por intuición y pillería, y afronta la misión de ascender a su principal representado como una cruzada. mientras la mayoría de los representantes mantiene las distancias con sus artistas, él ejerce de fiel compañero, siempre dispuesto a tomarse la última con un músico apegado a la noche. se van sucediendo los discos y sabina coge la ola buena: de cantautor de la mandrágora a llenar las ventas como rockero canalla. la oficina de lucena ya es una de las que más trabaja. por ella pasan javier ruibal, aute, manolo tena, barón rojo, burning, labordeta, la orquesta mondragón, jarabe de palo, una jovencísima malú…a finales de los ochenta decide atacar el mercado latinoamericano. “la compañía de discos no creía en joaquín triunfando allá. decían que no iban a entender su argot madrileño. lo tuve que hacer todo yo, tirando de teléfono y de contactos. el resultado es que desde hace 30 años joaquín es uno de los artistas más grandes del continente”, relata lucena, que se atribuye esa expansión.1996 fue su mejor año. se compró un mercedes por 10 millones de pesetas y un chalet en una zona exclusiva de madrid. sus vecinos eran víctor manuel y ana belén. la pareja lucena/sabina llevaba casi dos décadas trabajando juntos y apurando la noche. “nuestra relación no iba bien. joaquín suspendía muchos conciertos porque siempre estaba malo, sentíamos el desgaste, nos gritábamos…”, comenta. el 1998, según su relato, no aguanta más y presenta su dimisión. “pero a los dos meses me llama isabel oliart [madre de las dos hijas del músico] y me ruega que vaya a recoger a joaquín a buenos aires porque se ha peleado con fito páez [con quien estaba grabando el disco enemigos íntimos]”. lucena acepta, pero la relación entre los dos está contaminada.cuando solo llevan unas fechas de la gira de la considerada obra maestra de jienense, 19 días y 500 noches (año 2000), lucena recibe una llamada de jimena colorado, con la que el músico había iniciado una relación. “me pasa a joaquín, que me dice: ‘paco, después de lo que te voy a decir te cuelgo el teléfono: estás despedido”. ya no ha sabido nada de él en 21 años. “realmente a mí quien me echa es isabel oliart, que aunque no mantenga una relación sentimental con joaquín se ocupa de llevar su administración. yo le sobraba porque quería llevarlo todo ella”, comenta. este periódico se ha puesto en contacto con la secretaria de sabina, lena demartini, con la siguiente respuesta: “imposible organizar una entrevista con joaquín en este momento”.¿hubiera llegado tan lejos sabina sin la compañía de lucena? responde el periodista y escritor julio valdeón, autor de la biografía del cantante, sabina. sol y sombra (ed. efe eme, 2017): “paco lucena fue uno de esos manager que se forjan por accidente. un hombre inquieto, viajado y culto, que encuentra al cantautor de la mandrágora y lo acompaña en su ruta hacia el éxito. no es el responsable del éxito de sabina, pero no hay duda de que desempeñó un papel importante. uno que iba más allá de la gestión, no siempre canónica, todo hay que decirlo. digamos que entronca con el estilo de otros representantes míticos, que suplían el amateurismo del momento con toneladas de complicidad y entusiasmo”.“cuando me dejó joaquín yo estaba lleno de deudas. perdí 80 millones de pesetas en una compañía de discos que monté [don lucena discos, con álbumes de burning, javier ruibal, malevaje…], debía dinero de la gira que suspendimos con páez, tuve que despedir a ocho personas de mi oficina…”, relata. responde a esos agujeros con los 500.000 euros que ingresa por la contratación de parte de la gira de 19 días y 500 noches. “sí, he tenido dinero, he ganado millones de pesetas al mes, pero siempre lo invertía en música y estaba entrampado. nunca dispuse de grandes cantidades. la verdad es que no supe invertir bien lo que gané. además, nunca firmé contratos, porque soy un gilipollas. siempre he sellado los acuerdos dando la mano. ni con joaquín tuve un contrato”, reconoce.su último capítulo con sabina ocurrió el pasado 8 junio: llamó a la secretaria del músico, le contó su situación económica y solicitó hablar con él. llevaba 21 años sin intentar contactar con su exrepresentado. ella le dijo que se lo comentaría a joaquín.en 2000 vende su chalet y una casa en el centro de madrid para construirse una casa en moralzarzal, en la sierra de madrid. de 2000 a 2004 sigue ejerciendo de representante, “pero después de tener al más grande ya nada es igual”. su último representado es el lichis, ex la cabra mecánica. ya no disfruta de los lujos de antes, pero lleva una vida sin apreturas. el mercedes ya lo vendió. “mi situación precaria llega cuando me divorcio, en 2008, y me voy del chalet de moralzarzal para que viva mi ex con las dos niñas”, señala. se muda al piso que compró en 1970 su familia en aluche, donde todavía vivía su madre. y comienza su reclusión. a los tres años fallece la madre con 97 y se queda solo.todavía se considera marxista y la única persona en la política que le da plena confianza es yolanda díaz. sonríe cuando cuenta que el único que tiene las llaves de su casa es su vecino, fran, “un votante de vox”. “es buena gente: se las di por si me pasa algo”, asegura.su objetivo ahora es recuperar la mitad del dinero del chalet de moralzarzal, unos 250.000 euros, “para vivir un poco mejor” y publicar sus memorias a final de año con el título de pongamos que hablo de paco lucena. dice que no guarda contacto con ninguno de los músicos a los que representó y que con sus hijas, de 31 y 34 años, no se lleva demasiado bien. de los 680 que cobra cada mes debe abonar 200 a la persona que le pagó la nueva dentadura. “no tengo dinero, pero no me quejo. jamás me he quejado, en la vida. ‘caminando fui lo que fui’, como dice la canción de silvio rodríguez. he tenido dinero y poder, y ya no me interesan, porque te hacen ser ruin”.\n",
      "------------------------------------\n",
      "a finales de los setenta y principios de los ochenta prácticamente cualquier ciudad británica tenía una exuberante escena rock. el punk había dado paso a una nueva generación de grupos en una época abierta a todo, del pop más comercial a la vanguardia más experimental, y a aquellos chavales se les prometió que podían conquistar el mundo. solo se les exigía tener personalidad para sacar la cabeza en ese ecosistema superpoblado. algunos lo consiguieron, aunque fuera por 10 minutos. de liverpool, la ciudad natal de los beatles, salieron frankie goes to hollywood, china crisis, orchestral manoeuvres in the dark o the la’s, pero los más prometedores parecían the teardrop explodes, una banda de pop neopsicodélico liderada por julian cope, un educado universitario llegado de tamworth, una pequeña ciudad de clase media a 120 kilómetros de distancia.su carisma era grande. apenas sabían tocar cuando fueron fichados por zoo records, el sello de bill drummond, un peculiar personaje que años más tarde fundaría the klf y quemaría un millón de libras. el argumento de drummond era inapelable: el grupo de julian cope tenía el mejor nombre de la ciudad. fue cope quien recomendó el fichaje de la banda de un amigo, ian mcculloch. se llamaban echo & the bunnymen. el nombre no era tan bueno, pensó drummond, pero sí lo suficiente como para ser parte de zoo records.imaginen la desquiciada combinación. mcculloch persiguiendo la fama hasta el punto de que se pasaría años diciendo que u2 le robó el estilo y el éxito que le pertenecía. cope leyendo a william blake y consumiendo lsd en dosis salvajes. y drummond resulta que estaba obsesionado con la magia. cuentan que un día tuvo la revelación de que si echo & the bunnymen tocaban en islandia al mismo tiempo que the teardrop explodes lo hacían en papúa nueva guinea, y él se colocaba en un punto concreto de liverpool, algo pasaría. quizás le alcanzaría una poderosa descarga de energía. e intentó convencer a los grupos para que le siguieran el juego. “sí, quería canalizar el poder en mathew street, justo al lado de la estatua de carl jung. ese era su plan. bill es un tipo interesante”, cuenta julian cope por correo electrónico desde yatesbury, el pequeño pueblo inglés en el que vive, cerca del monumento de stonehenge. y continúa. “aquí en el norte, incluso los católicos han sentido el ardor del rotundo ‘no’ de lutero a la autoridad del papa. por eso, toda autoridad absoluta ha sido cuestionada en estas latitudes. aquí arriba somos paganos, idólatras”.¿se considera él mismo un mago? “mientras los medios ayudan a aquellos que necesitan tener un público para engordar su ego, creo que los magos realmente exitosos son aquellos cuyas carreras son largas y navegan sigilosamente”. si julian cope no habla como un músico pop es porque hace mucho que superó esa categoría. su carrera es larga, pero para nada sigilosa. publica discos, sí, pero también ha escrito una novela, dos guías sobre los monumentos megalíticos de gran bretaña y europa, una recopilación de reseñas de discos, muchos de ellos ignotos, que reescribe la historia del rock, y ensayos sobre el rock alemán y el japonés.este último, japrocksampler (contra), acaba de ser publicado en castellano 14 años después de su edición en inglés. “creo que el libro es tan completo como podría serlo cualquier obra que se defina como sampler. mi traductor japonés consiguió muchas historias que nunca se habían traducido, que le pedí que buscara y que requirieron mucha investigación, con los dos en el ordenador mirando webs de música japonesa underground”, dice.en el libro, erudito y apasionado, muestra su devoción por bandas tan peculiares como les rallizes dénudés, un grupo fundado en 1967 cuyo líder se ha negado siempre a hacerse fotografías y a grabar en un estudio, por lo que de ellos solo existen discos en directo, la mayoría piratas. su bajista original fue en 1970 uno de los terroristas miembros del ejército rojo japonés que secuestraron el vuelo 351 de japan airlines y lo desviaron a corea del norte, donde, de seguir vivo, aún reside. “cada uno de mis artistas favoritos se sitúa siempre en el filo de la cultura”, afirma cope.pero la clave de japrocksampler está en su subtítulo: “cómo el rock le voló la cabeza al japón de posguerra”. es la descripción de la completa rendición de aquel país a la cultura occidental. “después de la ii guerra mundial”, aclara cope, “los totalitarios necesitan que se les demuestre la inferioridad de sus posturas. una vez derrotados, entraron en razón: la democracia también tiene cosas buenas. alemania y japón habían actuado tan mal que se vieron obligados a cocacolizarse. sus tierras estaban inundadas de tropas extranjeras y sus medios de comunicación occidentalizados les decían lo que les tenía que gustar. creo que la música se volvió especialmente atractiva porque representaba la libertad y, sobre todo, una victoria”.resulta curioso que aquel bello y lánguido veinteañero que era julian cope se convirtiera en el excéntrico académico que es hoy. con 63 años, es un melenudo y barbudo elemento vestido de cuero y gorra militar, como un motorista de los setenta. se cuenta que, durante un tiempo, consumía tanto lsd que iba camino de ser el nuevo syd barrett, un mártir lisérgico del rock. “estaba un poco colgado en aquella época, pero no hubo ningún daño neurológico persistente”, asegura. “yo era un gilipollas muy tenso antes de tomar sustancias psicodélicas. después de hacerlo dejé de juzgar a los demás. me hizo más generoso en mi actitud hacia la gente y la vida”. ahora, casado y con dos hijas, lo ha dejado. “hice dos viajes con ácido en mi 50º cumpleaños. fue genial, hizo su trabajo. pero ninguno desde entonces”.se mueve en los márgenes de la industria. no tiene sello, edita sus discos y programa sus giras. no quiere saber nada del mainstream. the teardrop explodes duraron muy poco tiempo, apenas cuatro años, y nunca se han prestado a una de esas vueltas subvencionadas por un caché monstruoso pagado por grandes festivales. “ahora soy demasiado feo y no querría defraudar al público con un comportamiento anticuado”, justifica cope, que después del fin del grupo lo intentó en solitario, llegando a acumular un par de éxitos, world shut your mouth y trampolene, antes de bajarse definitivamente del tren. “no podía soportar el negocio de la música y sentía que la recompensa era demasiado escasa para toda esa comida de pollas corporativa que requería…”.puedes seguir a babelia en facebook y twitter, o apuntarte aquí para recibir nuestra newsletter semanal.\n",
      "------------------------------------\n",
      "pena que haya gilipollas como ella que sobrevivan mientras otros están bajo tierra.\n",
      "------------------------------------\n",
      "poco nos pasa. por gilipollas!! made in spain. #trogloditasiscoming\n",
      "------------------------------------\n",
      "vaya gilipollas. no te enteras. o estás demasiado cerca de la cúpula de tus jefes.\n",
      "------------------------------------\n",
      "no, no puedo considerarlos porque el que los personifica eres tú. los estados no existen como personas, para ser gilipollas o dejar de serlo\n",
      "------------------------------------\n",
      "@lavecinacotill3 perdooooooon!!?? paga semanal!!?? pero nos hemos vuelto gilipollas!!!???\n",
      "------------------------------------\n",
      "como los de nuestro gobierno populista , que ellos son un peligro y una pandilla de gilipollas comunistas\n",
      "------------------------------------\n",
      "definitivamente es gilipollas.\n",
      "------------------------------------\n",
      "@juanjborrero jajajjajajajaja no me jodas!!!,lo dice el que gobierna gracias al populismo fascista de vox??. en serio,estos políticos nos toman por gilipollas\n",
      "------------------------------------\n",
      "menuda rata de cloaca. pero ese tío q hace ahí!!’ somos gilipollas de verdad.\n",
      "------------------------------------\n",
      "@malcolm·ñ @filomeno vamos un gilipollas drogao a tiempo completo.\n",
      "------------------------------------\n",
      "de gilipollas está el mundo lleno...\n",
      "------------------------------------\n",
      "lógico, todos los que hemos visto esas películas somos racistas sin remedio....que gilipollas nos hemos vuelto.\n",
      "------------------------------------\n",
      "@helen_cor pero podéis seguir siendo gilipollas.\n",
      "------------------------------------\n",
      "tve paga por su directo, no por el paripé de madrid. esta es la televisión pública de españa, no de la españa dentro de españa de estos gilipollas\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "comentarios_gilipollas = no_odio[no_odio[\"CONTENIDO A ANALIZAR\"].str.contains(\"gilipollas\", case=False, na=False)]\n",
    "print(\"\\nComentarios de no odio que contienen la palabra 'gilipollas':\")\n",
    "\n",
    "for i in comentarios_gilipollas[\"CONTENIDO A ANALIZAR\"].to_list():\n",
    "    print(i)\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias a ver los comentarios que tienen \"gilipollas\" podemos ver claramente que muchos de ellos están etiquetados incorrectamente ya que tienen un sesgo despectivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    " \n",
    "Según el estudio que se ha llevado a cabo en este ejercicio podemos determinar que los comentarios de odio son de media mucho más cortos que los comentarios sin odio, pero si estos grupos se ven de cerca no tienen tanta diferenciam, ya que los dos grupos tienen un porcentaje notable, haciendo que no sea conclyente la longitud de los comentarios.\n",
    "\n",
    "A su misma vez no es concluyente estudiar la cantidad de entidades NER ni la cantidad de palabras de genero y número.\n",
    "\n",
    "Al contrario pasa si estuidiamos las palabras más usadas en los comentarios de odio y no odio, viendo que si contamos la frecuencia de palabras emocionalmente despectivas, podemos ver un a clara diferencia (+200%) en la frecuencia en el uso de estas palabras. Gracias a esto podemos llegar a la conclusión que en el uso de estas palabras hay una gran probabilidad de que este comentario sea de odio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
